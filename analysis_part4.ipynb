{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine latent scores using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant rows from male season scores in 2017 for toy example\n",
    "sample_season_scores = season_scores.loc[[1758, 1760, 1765, 1769, 1771, 1776, 1787]]\n",
    "\n",
    "# Transform long score table to pivot form\n",
    "season_pivot = pd.pivot_table(sample_season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "# Store skater and event names to retrieve later\n",
    "skater_names = list(season_pivot.index) # ['Alexander, MAJOROV', 'Javier, FERNANDEZ', 'Misha, GE', 'Takahito, MURA']\n",
    "event_names = list(season_pivot.columns) # ['CA', 'FR', 'RU']\n",
    "\n",
    "# Convert pivot table to numpy array\n",
    "true_scores = season_pivot.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -4.13612e-05\n"
     ]
    }
   ],
   "source": [
    "baseline, event_scores, skater_scores, rmse = batch_gd_multi(sample_season_scores, init_seed=42,\n",
    "alpha=0.0005, n_iter=1000, n_factors=2, return_rmse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_ranking = ['Javier, FERNANDEZ', 'Takahito, MURA', 'Misha, GE', 'Alexander, MAJOROV']\n",
    "skater_scores = skater_scores.reindex(world_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77421447,  0.7929066 ],\n",
       "       [ 1.62399575, -1.35273364],\n",
       "       [ 2.29622991,  0.74138494],\n",
       "       [ 0.84978128, -2.14564025],\n",
       "       [ 1.52201543, -0.05152167],\n",
       "       [ 0.67223415,  2.09411858]])"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_skater_scores = (skater_scores - skater_scores.mean(axis=0)) / skater_scores.std(axis=0)\n",
    "X = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normed_skater_scores.values, 2)))\n",
    "y = np.ones(len(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 998, avg ll: -0.13810343619496832\n",
      "i: 999, avg ll: -0.13801945599432072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.75780504, 0.14015987])"
      ]
     },
     "execution_count": 1228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = np.full(X.shape[1], 0.5)\n",
    "alpha = 0.001\n",
    "n_iter = 1000\n",
    "for i in range(n_iter):\n",
    "    prob = 1 / (1 + np.exp(-X @ beta))\n",
    "    gradient = (y - prob) @ X\n",
    "    beta = beta + alpha * gradient\n",
    "    \n",
    "    if i in [n_iter-2, n_iter-1]:\n",
    "        log_likelihood = y @ np.log(prob)\n",
    "        print(f'i: {i}, avg ll: {log_likelihood/len(X)}')\n",
    "    \n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 1229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (X @ beta) > 0\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Javier, FERNANDEZ', 'Takahito, MURA', 'Misha, GE', 'Alexander, MAJOROV']"
      ]
     },
     "execution_count": 1230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skaters = len(world_ranking)\n",
    "counter = [0] * n_skaters\n",
    "ordered_indices = combinations(range(n_skaters), 2)\n",
    "for y, (i, j) in zip(y_pred, ordered_indices):\n",
    "    if y == True:\n",
    "        counter[i] += 1\n",
    "    else:\n",
    "        counter[j] += 1\n",
    "        \n",
    "predicted_ranking = [skater for rank, skater in sorted(zip(counter, world_ranking), reverse=True)]\n",
    "predicted_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ranking(y_pred, world_ranking):\n",
    "    n_skaters = len(world_ranking)\n",
    "    counter = [0] * n_skaters\n",
    "    ordered_indices = combinations(range(n_skaters), 2)\n",
    "    for y, (i, j) in zip(y_pred, ordered_indices):\n",
    "        if y == True:\n",
    "            counter[i] += 1\n",
    "        else:\n",
    "            counter[j] += 1\n",
    "            \n",
    "    predicted_ranking = [skater for rank, skater in sorted(zip(counter, world_ranking), reverse=True)]\n",
    "    \n",
    "    return predicted_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Javier, FERNANDEZ', 'Takahito, MURA', 'Misha, GE', 'Alexander, MAJOROV']"
      ]
     },
     "execution_count": 1232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_ranking(y_pred, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for 2017 male skaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gradient_ascent(X, alpha=0.001, n_iter=1000, seed=42, log_ll=False):\n",
    "    random_state = np.random.RandomState(seed=seed)\n",
    "    beta = random_state.random_sample(X.shape[1])\n",
    "    beta = np.full(X.shape[1], 0.5)\n",
    "    y = np.ones(X.shape[0])\n",
    "    ll_log = []\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        prob = 1 / (1 + np.exp(-X @ beta))\n",
    "        gradient = (y - prob) @ X\n",
    "        beta = beta + alpha * gradient\n",
    "        \n",
    "        if log_ll:\n",
    "            ll = y @ np.log(prob)\n",
    "            ll_log.append(ll)\n",
    "        \n",
    "        if i in [n_iter-2, n_iter-1]:\n",
    "            log_likelihood = y @ np.log(prob)\n",
    "            print(f'i: {i}, avg ll: {log_likelihood/len(X)}')\n",
    "    \n",
    "    if log_ll:\n",
    "        return beta, lls\n",
    "    else:\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -8.7e-09\n"
     ]
    }
   ],
   "source": [
    "season_scores, world_scores = get_yearly_scores(2017, season_train, world_train)\n",
    "baseline, event_scores, skater_scores, rmse = batch_gd_multi(season_scores,\n",
    "alpha=0.0005, n_iter=1000, n_factors=50, return_rmse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "skater_scores = skater_scores.reindex(world_scores.index)\n",
    "normed_skater_scores = (skater_scores - skater_scores.mean(axis=0)) / skater_scores.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.31687959, -0.2671448 , -0.53267894, ..., -2.41102939,\n",
       "        -0.26444986,  1.00658698],\n",
       "       [ 2.9417398 , -0.27174558, -0.57801748, ..., -0.59997308,\n",
       "         0.05086234,  2.91090971],\n",
       "       [ 2.64362098,  0.55935797, -0.71593188, ..., -2.4838736 ,\n",
       "        -1.0189137 ,  2.93697039],\n",
       "       ...,\n",
       "       [ 1.21612145,  1.69646041,  0.6230803 , ..., -0.86580232,\n",
       "         0.43981237, -1.25332251],\n",
       "       [-0.13534635,  0.34437302, -0.47178943, ..., -0.31750738,\n",
       "         0.9221538 ,  0.20645316],\n",
       "       [-1.3514678 , -1.35208739, -1.09486974, ...,  0.54829494,\n",
       "         0.48234143,  1.45977567]])"
      ]
     },
     "execution_count": 1239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normed_skater_scores.values, 2)))\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 8, avg ll: -0.43778034660348003\n",
      "i: 9, avg ll: -0.417160939049043\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "beta = log_gradient_ascent(X, n_iter=10)\n",
    "print(((X @ beta) > 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (X @ beta) > 0\n",
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_scores = season_scores.groupby('name')['score'].mean()\n",
    "_, world_ranking = return_ranking(avg_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 242 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7536231884057971"
      ]
     },
     "execution_count": 1251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ranking = convert_to_ranking(y_pred, world_ranking)\n",
    "calculate_kendall_tau(predicted_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tau_from_X_beta(X, beta):\n",
    "    n_concordant_pairs = (X @ beta > 0).sum()\n",
    "    n_pairs = len(X)\n",
    "    return (2 * n_concordant_pairs - n_pairs) / n_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(seed=42)\n",
    "years1 = list(random_state.choice(train_years, size=5, replace=False))\n",
    "years2 = [year for year in train_years if year not in fold1_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = AverageScore()\n",
    "avg_result = avg.evaluate_over_years(all_years, all_season_scores, all_world_scores).set_index('year')\n",
    "avg_taus = avg_result['tau'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -8.477e-07\n",
      "2006\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.067e-07\n",
      "2007\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.3185e-06\n",
      "2009\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -4.556e-07\n",
      "2010\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.506e-07\n",
      "2012\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.71335e-05\n",
      "2013\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -6.67e-08\n",
      "2014\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -6.8911e-06\n",
      "2016\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.419e-07\n",
      "2017\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.428e-07\n"
     ]
    }
   ],
   "source": [
    "n_factors = 24\n",
    "X1 = {}\n",
    "X2 = {}\n",
    "\n",
    "for year in train_years:\n",
    "    print(year)\n",
    "    season_scores, world_scores = get_yearly_scores(year, season_train, world_train)\n",
    "    baseline, event_scores, skater_scores, rmse = batch_gd_multi(season_scores,\n",
    "    alpha=0.0005, n_iter=1000, n_factors=n_factors, return_rmse=True)\n",
    "    skater_scores = skater_scores.reindex(world_scores.index).dropna()\n",
    "    normed_skater_scores = (skater_scores - skater_scores.mean(axis=0)) / skater_scores.std(axis=0)\n",
    "    \n",
    "    X = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normed_skater_scores.values, 2)))\n",
    "    if year in years1:\n",
    "        X1[year] = X\n",
    "    else:\n",
    "        X2[year] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 998, avg ll: -0.3097380143378429\n",
      "i: 999, avg ll: -0.3097380143378429\n",
      "i: 998, avg ll: -0.3284659274864562\n",
      "i: 999, avg ll: -0.3284659274864562\n"
     ]
    }
   ],
   "source": [
    "beta1 = log_gradient_ascent(np.concatenate(list(X1.values())), n_iter=1000)\n",
    "beta2 = log_gradient_ascent(np.concatenate(list(X2.values())), n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtaus_train = {}\n",
    "dtaus_val = {}\n",
    "for year in years1:\n",
    "    dtaus_train[year] = get_tau_from_X_beta(X1[year], beta1) - avg_taus[year]\n",
    "    dtaus_val[year] = get_tau_from_X_beta(X1[year], beta2) - avg_taus[year]\n",
    "for year in years2:\n",
    "    dtaus_train[year] = get_tau_from_X_beta(X2[year], beta2) - avg_taus[year]\n",
    "    dtaus_val[year] = get_tau_from_X_beta(X2[year], beta1) - avg_taus[year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03762092979484284, -0.06860718991153775)"
      ]
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(dtaus_train.values())), np.mean(list(dtaus_val.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -4.703e-07\n",
      "2006\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.572e-07\n",
      "2007\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -3.4585e-06\n",
      "2008\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.7156e-06\n",
      "2009\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.1323e-06\n",
      "2010\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -6.089e-07\n",
      "2011\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.61129e-05\n",
      "2012\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.39693e-05\n",
      "2013\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -5.111e-07\n",
      "2014\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.01789e-05\n",
      "2015\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -7.024e-07\n",
      "2016\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.43e-07\n",
      "2017\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -1.2485e-06\n",
      "2018\n",
      "Alpha: 0.0005, Iter: 1000, Last RMSE: 0.0, Delta RMSE: -2.128e-07\n"
     ]
    }
   ],
   "source": [
    "X_train = {}\n",
    "X_test = {}\n",
    "\n",
    "for year in range(2005, 2019):\n",
    "    print(year)\n",
    "    season_scores, world_scores = get_yearly_scores(year, all_season_scores, all_world_scores)\n",
    "    baseline, event_scores, skater_scores, rmse = batch_gd_multi(season_scores,\n",
    "    alpha=0.0005, n_iter=1000, n_factors=n_factors, return_rmse=True)\n",
    "    skater_scores = skater_scores.reindex(world_scores.index).dropna()\n",
    "    normed_skater_scores = (skater_scores - skater_scores.mean(axis=0)) / skater_scores.std(axis=0)\n",
    "    \n",
    "    X = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normed_skater_scores.values, 2)))\n",
    "    if year in train_years:\n",
    "        X_train[year] = X\n",
    "    else:\n",
    "        X_test[year] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 998, avg ll: -0.34997204565608175\n",
      "i: 999, avg ll: -0.34997204565608175\n"
     ]
    }
   ],
   "source": [
    "beta_train = log_gradient_ascent(np.concatenate(list(X_train.values())), n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtaus_train = {}\n",
    "dtaus_test = {}\n",
    "\n",
    "for year in train_years:\n",
    "    dtaus_train[year] = get_tau_from_X_beta(X_train[year], beta_train) - avg_taus[year]\n",
    "for year in test_years:\n",
    "    dtaus_test[year] = get_tau_from_X_beta(X_test[year], beta_train) - avg_taus[year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05571240353849048"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(dtaus_test.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
