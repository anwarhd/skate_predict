{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from scipy.stats import kendalltau\n",
    "from batchlog import BatchLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "plt.style.use('seaborn')\n",
    "rc('text', usetex=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scores from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_scores = pd.read_csv('scores/trimmed_male.csv')\n",
    "female_scores = pd.read_csv('scores/trimmed_female.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2005, 2006, 2007, 2009, 2010, 2012, 2013, 2014, 2016, 2017],\n",
       " [2008, 2011, 2015, 2018])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_before_last = range(2005, 2018)\n",
    "year_seed = np.random.RandomState(seed=42)\n",
    "train_years = sorted(list(year_seed.choice(years_before_last, size=10, replace=False)))\n",
    "test_years = sorted([year for year in years_before_last if year not in train_years] + [2018])\n",
    "train_years, test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(scores, train_years, test_years):\n",
    "    season_scores = scores.loc[scores['event']!='WR']\n",
    "    world_scores = scores.loc[scores['event']=='WR']\n",
    "    \n",
    "    season_train = season_scores.loc[season_scores['year'].isin(train_years)]\n",
    "    world_train = world_scores.loc[world_scores['year'].isin(train_years)]\n",
    "    season_test = season_scores.loc[season_scores['year'].isin(test_years)]\n",
    "    world_test = world_scores.loc[world_scores['year'].isin(test_years)]    \n",
    "    \n",
    "    return season_train, world_train, season_test, world_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1216, 4), (238, 4), (507, 4), (96, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_train, world_train, season_test, world_test = train_test_split(male_scores, train_years, test_years)\n",
    "season_train.shape, world_train.shape, season_test.shape, world_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement kendall tau metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ranking(skater_scores, world_scores):\n",
    "    skater_scores = skater_scores.sort_values(ascending=False)\n",
    "    world_scores = world_scores.sort_values(ascending=False)\n",
    "    skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "    world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "    return skater_ranking, world_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kendall_tau(skater_ranking, world_ranking, verbose=True):\n",
    "    skater_pairs = set(combinations(skater_ranking, 2))\n",
    "    world_pairs = set(combinations(world_ranking, 2))\n",
    "    n_pairs = len(skater_pairs)\n",
    "    n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "    print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "    tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "    return tau "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average skate score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "season_scores = season_train.loc[season_train['year']==year].copy()\n",
    "world_scores = world_train.loc[world_train['year']==year, ['name', 'score']].set_index('name').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        290.5350\n",
       "Javier, FERNANDEZ    285.4925\n",
       "Shoma, UNO           283.7425\n",
       "Nathan, CHEN         281.0050\n",
       "Patrick, CHAN        270.3500\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_avg = season_scores.groupby('name')['score'].mean().sort_values(ascending=False)\n",
    "season_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 234 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ranking, world_ranking = return_ranking(season_avg, world_scores)\n",
    "calculate_kendall_tau(avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result agrees with kendalltau from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.6956521739130435, pvalue=1.9126097800691154e-06)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_numeric_rank = list(range(len(avg_ranking)))\n",
    "world_numeric_rank = [avg_ranking.index(skater) for skater in world_ranking]\n",
    "kendalltau(season_numeric_rank, world_numeric_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE with mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.271546837961868"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison = pd.merge(season_scores, season_avg.to_frame(), left_on='name', right_index=True, suffixes=['', '_avg'])\n",
    "score_comparison['sq_error'] = (score_comparison['score'] - score_comparison['score_avg'])**2\n",
    "np.sqrt(score_comparison['sq_error'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_scores(year, season_scores, world_scores):\n",
    "    yearly_season_scores = season_scores.loc[season_scores['year']==year].copy()\n",
    "    yearly_world_scores = world_scores.loc[world_scores['year']==year, ['name', 'score']].set_index('name').squeeze()\n",
    "    return yearly_season_scores, yearly_world_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.skater_scores = None\n",
    "        self.model_ranking = None\n",
    "        self.world_ranking = None\n",
    "        self.predicted_season_scores = None\n",
    "    \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        squared_errors = (season_scores['score'].values - self.predicted_season_scores)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        return rmse\n",
    "        \n",
    "    def evaluate_kendall_tau(self, world_scores, verbose=True):\n",
    "        def return_ranking(skater_scores, world_scores):\n",
    "            skater_scores = skater_scores.sort_values(ascending=False)\n",
    "            world_scores = world_scores.sort_values(ascending=False)\n",
    "            skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "            world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "            return skater_ranking, world_ranking\n",
    "    \n",
    "        def calculate_kendall_tau(skater_ranking, world_ranking, verbose=verbose):\n",
    "            skater_pairs = set(combinations(skater_ranking, 2))\n",
    "            world_pairs = set(combinations(world_ranking, 2))\n",
    "            n_pairs = len(skater_pairs)\n",
    "            n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "            if verbose:\n",
    "                print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "            tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "            return tau, n_concordant_pairs, n_pairs\n",
    "        \n",
    "        self.model_ranking, self.world_ranking = return_ranking(self.skater_scores, world_scores)\n",
    "        return calculate_kendall_tau(self.model_ranking, self.world_ranking)\n",
    "    \n",
    "    def evaluate_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        taus = []\n",
    "        rmses = []\n",
    "        concordant_pairs = []\n",
    "        n_pairs = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            tau, concordant_pair, n_pair = self.evaluate_kendall_tau(world_scores, verbose=False)\n",
    "            \n",
    "            rmses.append(rmse)\n",
    "            taus.append(tau)\n",
    "            concordant_pairs.append(concordant_pair)\n",
    "            n_pairs.append(n_pair)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses, \n",
    "                             'tau': taus, 'conc': concordant_pairs, 'pairs': n_pairs}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        self.predicted_season_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "    \n",
    "    def fit(self, season_scores):\n",
    "        self.skater_scores = season_scores.groupby('name')['score'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.predict_season_scores(season_scores)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_train_eval = avg.evaluate_over_years(train_years, season_train, world_train)\n",
    "avg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_scores['score_normed'] = season_scores.groupby('event')['score'].transform(lambda score: (score - score.mean()) / score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        1.668135\n",
       "Javier, FERNANDEZ    1.440927\n",
       "Shoma, UNO           1.326910\n",
       "Nathan, CHEN         1.104096\n",
       "Patrick, CHAN        1.090843\n",
       "Name: score_normed, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_normed_avg = season_scores.groupby('name')['score_normed'].mean().sort_values(ascending=False)\n",
    "season_normed_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 222 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6086956521739131"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_avg_ranking, world_ranking = return_ranking(season_normed_avg, world_scores)\n",
    "calculate_kendall_tau(normed_avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormedAverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def predict_season_scores(self, season_scores, event_stds, event_means):\n",
    "        self.predicted_season_scores = (self.skater_scores.loc[season_scores['name']] * event_stds + event_means).values\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        season_scores = season_scores.copy()\n",
    "        event_means = season_scores.groupby('event')['score'].mean().loc[season_scores['event']].values\n",
    "        event_stds = season_scores.groupby('event')['score'].std().loc[season_scores['event']].values\n",
    "        season_scores['score_normed'] = (season_scores['score'] - event_means) / event_stds\n",
    "        \n",
    "        self.skater_scores = season_scores.groupby('name')['score_normed'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        self.predict_season_scores(season_scores, event_stds, event_means)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>14.221490</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>166</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>12.650485</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>12.556444</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>14.067104</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.898410</td>\n",
       "      <td>0.593074</td>\n",
       "      <td>184</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.437599</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>15.373393</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>15.685363</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>177</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>18.328151</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>15.921112</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>222</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  14.221490  0.580952   166    210\n",
       "1  2006  12.650485  0.636364   207    253\n",
       "2  2007  12.556444  0.630435   225    276\n",
       "3  2009  14.067104  0.615942   223    276\n",
       "4  2010  12.898410  0.593074   184    231\n",
       "5  2012  12.437599  0.494071   189    253\n",
       "6  2013  15.373393  0.494071   189    253\n",
       "7  2014  15.685363  0.685714   177    210\n",
       "8  2016  18.328151  0.615942   223    276\n",
       "9  2017  15.921112  0.608696   222    276"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normavg = NormedAverageScore()\n",
    "normavg_train_eval = normavg.evaluate_over_years(train_years, season_train, world_train)\n",
    "normavg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "season_scores = season_train.loc[season_train['year']==year].copy()\n",
    "world_scores = world_train.loc[world_train['year']==year, ['name', 'score']].set_index('name').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "unique_skaters = season_scores['name'].unique()\n",
    "unique_events = season_scores['event'].unique()\n",
    "\n",
    "dummies_skater_count = len(unique_skaters) - 1\n",
    "dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "dropped_event = list(set(unique_events) - set(dummies_events))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "        -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "        -45.88750626,  -35.41149857])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dummies.values\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "y = season_scores['score'].values\n",
    "coefs_linear = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "coefs_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_rmse = np.sqrt(np.mean((y - X @ coefs_linear)**2))\n",
    "linear_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "         -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "         -45.88750626,  -35.41149857]), 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, y)\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y, X @ lin.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropped baseline skater and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Model):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.event_scores = None\n",
    "        self.baseline = None\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ y)\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "        unique_skaters = season_scores['name'].unique()\n",
    "        unique_events = season_scores['event'].unique()\n",
    "        \n",
    "        dummies_skater_count = len(unique_skaters) - 1\n",
    "        dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "        dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "        dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "        dropped_event = list(set(unique_events) - set(dummies_events))[0]\n",
    "\n",
    "        X = dummies.values\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        y = season_scores['score'].values\n",
    "        coefs = self.find_coefs(X, y)\n",
    "\n",
    "        self.baseline = coefs[0]    \n",
    "        self.skater_scores = pd.Series(coefs[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "        self.event_scores = pd.Series(coefs[dummies_skater_count+1:], index=dummies_events)\n",
    "        self.skater_scores[dropped_skater] = 0\n",
    "        self.event_scores[dropped_event] = 0\n",
    "        \n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(ascending=False, inplace=True)        \n",
    "        \n",
    "        self.predict_season_scores(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.555327</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.883763</td>\n",
       "      <td>0.620553</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.578146</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.110917</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>219</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.798364</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>196</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.144647</td>\n",
       "      <td>0.541502</td>\n",
       "      <td>195</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.047367</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.781486</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>190</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.053367</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.838700</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.555327  0.666667   175    210\n",
       "1  2006   7.883763  0.620553   205    253\n",
       "2  2007   7.578146  0.601449   221    276\n",
       "3  2009   8.110917  0.586957   219    276\n",
       "4  2010   9.798364  0.696970   196    231\n",
       "5  2012   8.144647  0.541502   195    253\n",
       "6  2013   9.047367  0.691700   214    253\n",
       "7  2014   8.781486  0.809524   190    210\n",
       "8  2016  11.053367  0.673913   231    276\n",
       "9  2017   8.838700  0.731884   239    276"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear()\n",
    "linear_train_eval = linear.evaluate_over_years(train_years, season_train, world_train)\n",
    "linear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.662111801242236"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.779208324854647 0.662111801242236\n",
      "0.001 8.782755125399937 0.6619499341238472\n",
      "0.01 8.925173433616132 0.6596894409937888\n",
      "0.1 9.788140496081605 0.6537982307547525\n",
      "1 15.206034467688387 0.637331074722379\n",
      "10 27.042844923858063 0.6193073593073594\n",
      "100 32.34814733209342 0.6250574063617542\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    linear = Linear(lambda_reg=lambda_reg)\n",
    "    linear_train_eval = linear.evaluate_over_years(train_years, season_train, world_train)\n",
    "    print(lambda_reg, linear_train_eval['rmse'].mean(), linear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "       -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_log_linear = np.linalg.inv(X.T @ X) @ (X.T @ np.log(y))\n",
    "coefs_log_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_linear_rmse = np.exp(np.sqrt(np.mean((np.log(y) - X @ coefs_log_linear)**2)))\n",
    "log_linear_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_log_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_log_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "skater_scores = np.exp(skater_scores)\n",
    "event_scores = np.exp(event_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  1.154228\n",
       "Nathan, CHEN                   1.110905\n",
       "Javier, FERNANDEZ              1.108103\n",
       "Shoma, UNO                     1.105957\n",
       "Patrick, CHAN                  1.062009\n",
       "Denis, TEN                     1.059121\n",
       "Boyang, JIN                    1.014664\n",
       "Adam, RIPPON                   1.000000\n",
       "Jason, BROWN                   0.953747\n",
       "Sergei, VORONOV                0.947786\n",
       "Alexei, BYCHENKO               0.937530\n",
       "Mikhail, KOLYADA               0.933023\n",
       "Takahito, MURA                 0.932946\n",
       "Max, AARON                     0.928603\n",
       "Kevin, REYNOLDS                0.912023\n",
       "Maxim, KOVTUN                  0.911407\n",
       "Misha, GE                      0.906351\n",
       "Keiji, TANAKA                  0.905789\n",
       "Nam, NGUYEN                    0.898441\n",
       "Alexander, PETROV              0.892819\n",
       "Jorik, HENDRICKX               0.891376\n",
       "Moris, KVITELASHVILI           0.880480\n",
       "Timothy, DOLENSKY              0.877638\n",
       "Han, YAN                       0.875485\n",
       "Gordei, GORSHKOV               0.869104\n",
       "Daniel, SAMOHIN                0.867256\n",
       "Chafik, BESSEGHIER             0.865572\n",
       "Artur, DMITRIEV                0.860806\n",
       "Deniss, VASILJEVS              0.856720\n",
       "Alexander, SAMARIN             0.853385\n",
       "                                 ...   \n",
       "Michal, BREZINA                0.841853\n",
       "Elladj, BALDE                  0.835828\n",
       "Paul, FENTZ                    0.834829\n",
       "Grant, HOCHSTEIN               0.831686\n",
       "Brendan, KERRY                 0.822836\n",
       "Michael Christian, MARTINEZ    0.815368\n",
       "Ross, MINER                    0.807469\n",
       "Alexander, MAJOROV             0.775878\n",
       "Julian Zhi Jie, YEE            0.771658\n",
       "Ivan, RIGHINI                  0.753486\n",
       "Ivan, PAVLOV                   0.749886\n",
       "Sihyeong, LEE                  0.745196\n",
       "Jinseo, KIM                    0.742645\n",
       "Kevin, AYMOZ                   0.737319\n",
       "Graham, NEWBERRY               0.732107\n",
       "Stephane, WALKER               0.727227\n",
       "Javier, RAYA                   0.722792\n",
       "June Hyoung, LEE               0.714204\n",
       "Maurizio, ZANDRON              0.689007\n",
       "Jiri, BELOHRADSKY              0.671338\n",
       "Slavik, HAYRAPETYAN            0.668233\n",
       "Daniel Albert, NAURITS         0.650934\n",
       "Chih-I, TSAO                   0.645860\n",
       "Andrew, DODDS                  0.616999\n",
       "Mark, WEBSTER                  0.609308\n",
       "Valtter, VIRTANEN              0.606540\n",
       "Sondre, ODDVOLL BOE            0.601957\n",
       "Leslie, IP                     0.558707\n",
       "Kai Xiang, CHEW                0.527181\n",
       "Micah, TANG                    0.517015\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skater_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "        -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472]), 0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, np.log(y))\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.sqrt(mean_squared_error(np.log(y), X @ lin.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Kendall's Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLinear(Linear):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ np.log(y))\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.log_predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        self.predicted_season_scores = np.exp(self.log_predicted_season_scores)\n",
    "        \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        log_squared_errors = (np.log(season_scores['score'].values) - self.log_predicted_season_scores)**2\n",
    "        log_rmse = np.sqrt(log_squared_errors.mean())\n",
    "        rmse = np.exp(log_rmse)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>1.051008</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.045100</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>1.042015</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1.042605</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>216</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.050437</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.040119</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>193</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.041869</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>213</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>1.040164</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.048652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      rmse       tau  conc  pairs\n",
       "0  2005  1.051008  0.666667   175    210\n",
       "1  2006  1.045100  0.636364   207    253\n",
       "2  2007  1.042015  0.601449   221    276\n",
       "3  2009  1.042605  0.565217   216    276\n",
       "4  2010  1.050437  0.714286   198    231\n",
       "5  2012  1.040119  0.525692   193    253\n",
       "6  2013  1.041869  0.683794   213    253\n",
       "7  2014  1.040164  0.828571   192    210\n",
       "8  2016  1.048652  0.673913   231    276\n",
       "9  2017  1.037668  0.731884   239    276"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear = LogLinear()\n",
    "loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_train, world_train)\n",
    "loglinear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627837380011293"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.evaluate_over_years(train_years, season_train, world_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.043963617896676 0.6627837380011293\n",
      "0.001 1.043998390360219 0.6618520609824958\n",
      "0.01 1.0453133728174064 0.653425559947299\n",
      "0.1 1.0518538623368006 0.6394089968003012\n",
      "1 1.087499139738013 0.6379691323169585\n",
      "10 1.162036606713829 0.6258008658008658\n",
      "100 1.1945282438818492 0.6286598908338039\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    loglinear = LogLinear(lambda_reg=lambda_reg)\n",
    "    loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_train, world_train)\n",
    "    print(lambda_reg, loglinear_train_eval['rmse'].mean(), loglinear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "skater_names = list(season_table.index)\n",
    "event_names = list(season_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scores = season_table.values\n",
    "skater_scores = np.full(len(skater_names), 0.5)\n",
    "event_scores = np.full(len(event_names), 0.5)\n",
    "bias = 0.5\n",
    "\n",
    "alpha = 0.0001\n",
    "rmses = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    diff = np.outer(skater_scores, event_scores) + bias - true_scores\n",
    "    event_gradients = np.nansum(diff * event_scores, axis=0)\n",
    "    skater_gradients = np.nansum(diff.T * skater_scores, axis=0)\n",
    "    bias_gradient = np.nansum(diff)\n",
    "    \n",
    "    event_scores = event_scores - alpha * event_gradients\n",
    "    skater_scores = skater_scores - alpha * skater_gradients\n",
    "    bias = bias - alpha * bias_gradient\n",
    "    rmse = np.sqrt(np.nanmean(diff**2))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.868466606229298"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f32366847b8>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  1.894050\n",
       "Nathan, CHEN                   1.803551\n",
       "Javier, FERNANDEZ              1.790822\n",
       "Shoma, UNO                     1.789057\n",
       "Patrick, CHAN                  1.703897\n",
       "Denis, TEN                     1.696405\n",
       "Boyang, JIN                    1.610850\n",
       "Adam, RIPPON                   1.580097\n",
       "Jason, BROWN                   1.490344\n",
       "Sergei, VORONOV                1.472533\n",
       "Takahito, MURA                 1.447655\n",
       "Alexei, BYCHENKO               1.446761\n",
       "Mikhail, KOLYADA               1.437773\n",
       "Max, AARON                     1.429594\n",
       "Kevin, REYNOLDS                1.406148\n",
       "Maxim, KOVTUN                  1.403931\n",
       "Misha, GE                      1.391367\n",
       "Keiji, TANAKA                  1.386313\n",
       "Nam, NGUYEN                    1.374465\n",
       "Alexander, PETROV              1.362922\n",
       "Jorik, HENDRICKX               1.358675\n",
       "Moris, KVITELASHVILI           1.335439\n",
       "Timothy, DOLENSKY              1.333063\n",
       "Han, YAN                       1.330643\n",
       "Daniel, SAMOHIN                1.311808\n",
       "Gordei, GORSHKOV               1.307350\n",
       "Chafik, BESSEGHIER             1.303317\n",
       "Artur, DMITRIEV                1.293111\n",
       "Deniss, VASILJEVS              1.285871\n",
       "Alexander, SAMARIN             1.281719\n",
       "                                 ...   \n",
       "Ryuju, HINO                    1.257658\n",
       "Paul, FENTZ                    1.244928\n",
       "Grant, HOCHSTEIN               1.243781\n",
       "Elladj, BALDE                  1.243484\n",
       "Brendan, KERRY                 1.224216\n",
       "Michael Christian, MARTINEZ    1.209809\n",
       "Ross, MINER                    1.191236\n",
       "Alexander, MAJOROV             1.127028\n",
       "Julian Zhi Jie, YEE            1.122074\n",
       "Ivan, RIGHINI                  1.083467\n",
       "Ivan, PAVLOV                   1.076504\n",
       "Sihyeong, LEE                  1.068961\n",
       "Jinseo, KIM                    1.063841\n",
       "Kevin, AYMOZ                   1.051584\n",
       "Graham, NEWBERRY               1.041249\n",
       "Stephane, WALKER               1.031574\n",
       "Javier, RAYA                   1.022778\n",
       "June Hyoung, LEE               1.006756\n",
       "Maurizio, ZANDRON              0.955782\n",
       "Jiri, BELOHRADSKY              0.920743\n",
       "Slavik, HAYRAPETYAN            0.914586\n",
       "Daniel Albert, NAURITS         0.880278\n",
       "Chih-I, TSAO                   0.869590\n",
       "Andrew, DODDS                  0.811672\n",
       "Mark, WEBSTER                  0.796238\n",
       "Valtter, VIRTANEN              0.792227\n",
       "Sondre, ODDVOLL BOE            0.783135\n",
       "Leslie, IP                     0.694706\n",
       "Kai Xiang, CHEW                0.631470\n",
       "Micah, TANG                    0.611085\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_scores = pd.Series(skater_scores, index=skater_names)\n",
    "hybrid_scores.sort_values(ascending=False, inplace=True)\n",
    "hybrid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_ranking, world_ranking = return_ranking(hybrid_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(hybrid_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(Linear):\n",
    "    def __init__(self, alpha, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.predicted_season_scores = broadcasted_skater_scores * broadcasted_event_scores + self.baseline\n",
    "        \n",
    "    def fit(self, season_scores, n_iter):\n",
    "        season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "        skater_names = list(season_table.index)\n",
    "        event_names = list(season_table.columns)\n",
    "\n",
    "        true_scores = season_table.values\n",
    "        self.skater_scores = np.full(len(skater_names), 0.5)\n",
    "        self.event_scores = np.full(len(event_names), 0.5)\n",
    "        self.baseline = 0.5\n",
    "\n",
    "        self.rmses = []\n",
    "\n",
    "        for _ in range(n_iter):\n",
    "            diff = np.outer(self.skater_scores, self.event_scores) + self.baseline - true_scores\n",
    "            baseline_gradient = np.nansum(diff)\n",
    "            skater_gradients = np.nansum(diff.T * self.skater_scores, axis=0) + self.lambda_reg * self.skater_scores\n",
    "            event_gradients = np.nansum(diff * self.event_scores, axis=0) + self.lambda_reg * self.event_scores            \n",
    "            \n",
    "            self.baseline = self.baseline - self.alpha * baseline_gradient\n",
    "            self.skater_scores = self.skater_scores - self.alpha * skater_gradients\n",
    "            self.event_scores = self.event_scores - self.alpha * event_gradients\n",
    "            rmse = np.sqrt(np.nanmean(diff**2))\n",
    "            self.rmses.append(rmse)\n",
    "            \n",
    "        self.skater_scores = pd.Series(self.skater_scores, index=skater_names)\n",
    "        self.event_scores = pd.Series(self.event_scores, index=event_names)\n",
    "        \n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(ascending=False, inplace=True)        \n",
    "        \n",
    "        self.predict_season_scores(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.0001)\n",
    "hybrid.fit(season_scores, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.908784359157266"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  1.894050\n",
       "Nathan, CHEN                   1.803551\n",
       "Javier, FERNANDEZ              1.790822\n",
       "Shoma, UNO                     1.789057\n",
       "Patrick, CHAN                  1.703897\n",
       "Denis, TEN                     1.696405\n",
       "Boyang, JIN                    1.610850\n",
       "Adam, RIPPON                   1.580097\n",
       "Jason, BROWN                   1.490344\n",
       "Sergei, VORONOV                1.472533\n",
       "Takahito, MURA                 1.447655\n",
       "Alexei, BYCHENKO               1.446761\n",
       "Mikhail, KOLYADA               1.437773\n",
       "Max, AARON                     1.429594\n",
       "Kevin, REYNOLDS                1.406148\n",
       "Maxim, KOVTUN                  1.403931\n",
       "Misha, GE                      1.391367\n",
       "Keiji, TANAKA                  1.386313\n",
       "Nam, NGUYEN                    1.374465\n",
       "Alexander, PETROV              1.362922\n",
       "Jorik, HENDRICKX               1.358675\n",
       "Moris, KVITELASHVILI           1.335439\n",
       "Timothy, DOLENSKY              1.333063\n",
       "Han, YAN                       1.330643\n",
       "Daniel, SAMOHIN                1.311808\n",
       "Gordei, GORSHKOV               1.307350\n",
       "Chafik, BESSEGHIER             1.303317\n",
       "Artur, DMITRIEV                1.293111\n",
       "Deniss, VASILJEVS              1.285871\n",
       "Alexander, SAMARIN             1.281719\n",
       "                                 ...   \n",
       "Ryuju, HINO                    1.257658\n",
       "Paul, FENTZ                    1.244928\n",
       "Grant, HOCHSTEIN               1.243781\n",
       "Elladj, BALDE                  1.243484\n",
       "Brendan, KERRY                 1.224216\n",
       "Michael Christian, MARTINEZ    1.209809\n",
       "Ross, MINER                    1.191236\n",
       "Alexander, MAJOROV             1.127028\n",
       "Julian Zhi Jie, YEE            1.122074\n",
       "Ivan, RIGHINI                  1.083467\n",
       "Ivan, PAVLOV                   1.076504\n",
       "Sihyeong, LEE                  1.068961\n",
       "Jinseo, KIM                    1.063841\n",
       "Kevin, AYMOZ                   1.051584\n",
       "Graham, NEWBERRY               1.041249\n",
       "Stephane, WALKER               1.031574\n",
       "Javier, RAYA                   1.022778\n",
       "June Hyoung, LEE               1.006756\n",
       "Maurizio, ZANDRON              0.955782\n",
       "Jiri, BELOHRADSKY              0.920743\n",
       "Slavik, HAYRAPETYAN            0.914586\n",
       "Daniel Albert, NAURITS         0.880278\n",
       "Chih-I, TSAO                   0.869590\n",
       "Andrew, DODDS                  0.811672\n",
       "Mark, WEBSTER                  0.796238\n",
       "Valtter, VIRTANEN              0.792227\n",
       "Sondre, ODDVOLL BOE            0.783135\n",
       "Leslie, IP                     0.694706\n",
       "Kai Xiang, CHEW                0.631470\n",
       "Micah, TANG                    0.611085\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.skater_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EU    136.463848\n",
       "4C    130.832781\n",
       "RU    128.192951\n",
       "CN    128.178315\n",
       "US    128.003822\n",
       "FR    125.767991\n",
       "FN    122.370908\n",
       "CA    122.042710\n",
       "JP    120.264202\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.event_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7318840579710145, 239, 276)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.evaluate_kendall_tau(world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.868465563978589"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.evaluate_rmse(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.631511</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.951620</td>\n",
       "      <td>0.628458</td>\n",
       "      <td>206</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.633914</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>222</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.185841</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>220</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.755347</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>196</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.310617</td>\n",
       "      <td>0.541502</td>\n",
       "      <td>195</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>8.938449</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.805313</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.019698</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.868466</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.631511  0.666667   175    210\n",
       "1  2006   7.951620  0.628458   206    253\n",
       "2  2007   7.633914  0.608696   222    276\n",
       "3  2009   8.185841  0.594203   220    276\n",
       "4  2010   9.755347  0.696970   196    231\n",
       "5  2012   8.310617  0.541502   195    253\n",
       "6  2013   8.938449  0.691700   214    253\n",
       "7  2014   8.805313  0.828571   192    210\n",
       "8  2016  11.019698  0.673913   231    276\n",
       "9  2017   8.868466  0.731884   239    276"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, n_iter=1000)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.810077535097456, 8.779208324854647, 1.043963617896676, 10.087526233651136)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_train_eval['rmse'].mean(), linear_train_eval['rmse'].mean(), loglinear_train_eval['rmse'].mean(), avg_train_eval['rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6662563523433088, 0.662111801242236, 0.6627837380011293, 0.6705326557500471)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyrbid_train_eval['tau'].mean(), linear_train_eval['tau'].mean(), loglinear_train_eval['tau'].mean(), avg_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 8.811618446776853 0.6662563523433088\n",
      "0.6 8.81203784343687 0.6662563523433088\n",
      "0.7 8.812494213174094 0.6669809900244682\n",
      "0.7999999999999999 8.812987513303364 0.6669809900244682\n",
      "0.8999999999999999 8.81351770088724 0.6669809900244682\n",
      "0.9999999999999999 8.814084732742904 0.6685620176924524\n",
      "1.0999999999999999 8.814688565449144 0.667837380011293\n",
      "1.1999999999999997 8.815329155353336 0.667837380011293\n",
      "1.2999999999999998 8.816006458578538 0.667837380011293\n",
      "1.4 8.816720431030586 0.667837380011293\n",
      "1.4999999999999998 8.81747102840529 0.667837380011293\n",
      "1.5999999999999996 8.81825820619563 0.667837380011293\n",
      "1.6999999999999997 8.819081919699036 0.667837380011293\n",
      "1.7999999999999998 8.819942124024708 0.667837380011293\n",
      "1.8999999999999997 8.82083877410097 0.667837380011293\n",
      "1.9999999999999996 8.821771824682699 0.6670468661773009\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in np.arange(0.5, 2.1, 0.1):\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.0001)\n",
    "    hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, n_iter=1000)\n",
    "    print(lambda_reg, hybrid_train_eval['rmse'].mean(), hybrid_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 8.771835172968178 0.6051665725578769\n",
      "0.6 8.772163461487398 0.6051665725578769\n",
      "0.7 8.772523718784464 0.6051665725578769\n",
      "0.7999999999999999 8.772915902009178 0.6051665725578769\n",
      "0.8999999999999999 8.773339967812838 0.6051665725578769\n",
      "0.9999999999999999 8.773795872351391 0.6051665725578769\n",
      "1.0999999999999999 8.774283571288585 0.6051665725578769\n",
      "1.1999999999999997 8.774803019799219 0.6051665725578769\n",
      "1.2999999999999998 8.775354172572415 0.6051665725578769\n",
      "1.4 8.775936983814944 0.6051665725578769\n",
      "1.4999999999999998 8.77655140725462 0.6030020703933747\n",
      "1.5999999999999996 8.777197396143729 0.6030020703933747\n",
      "1.6999999999999997 8.777874903262493 0.6051665725578769\n",
      "1.7999999999999998 8.77858388092263 0.6051665725578769\n",
      "1.8999999999999997 8.779324280970915 0.6051665725578769\n",
      "1.9999999999999996 8.78009605479281 0.6051665725578769\n",
      "0.0 8.77067472651979 0.6051665725578769\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in np.append(np.arange(0.5, 2.1, 0.1), [0]):\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.0001)\n",
    "    hybrid_train_eval = hybrid.evaluate_over_years(test_years, season_test, world_test, n_iter=1000)\n",
    "    print(lambda_reg, hybrid_train_eval['rmse'].mean(), hybrid_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6094955768868812"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_test_eval = avg.evaluate_over_years(test_years, season_test, world_test)\n",
    "avg_test_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-0281707b6d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlinear_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_linear_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mall_scores_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mall_scores_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_scores' is not defined"
     ]
    }
   ],
   "source": [
    "all_scores = pd.concat([linear_scores, log_linear_scores, hybrid_scores], axis=1, sort=True)\n",
    "all_scores = all_scores.reindex(world_scores.index).values\n",
    "all_scores_mean = all_scores.mean(axis=0)\n",
    "all_scores_std = all_scores.std(axis=0)\n",
    "all_scores = (all_scores - all_scores_mean) / all_scores_std\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(all_scores, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_scores[:, 1], all_scores[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_status = np.full(len(score_diffs), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = BatchLogistic(theta=[0.5, 0.5, 0.5], alpha=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(score_diffs, pairwise_status, n_iter=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(log.avg_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_scores = pd.Series(all_scores @ log.theta, index=world_scores.index).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ranking, world_ranking = return_ranking(combined_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_kendall_tau(combined_ranking, world_ranking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
