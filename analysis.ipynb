{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from scipy.stats import kendalltau\n",
    "from batchlog import BatchLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "plt.style.use('seaborn')\n",
    "rc('text', usetex=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scores from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_scores = pd.read_csv('scores/trimmed_male.csv')\n",
    "female_scores = pd.read_csv('scores/trimmed_female.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2005, 2006, 2007, 2009, 2010, 2012, 2013, 2014, 2016, 2017],\n",
       " [2008, 2011, 2015, 2018])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_before_last = range(2005, 2018)\n",
    "year_seed = np.random.RandomState(seed=42)\n",
    "train_years = sorted(list(year_seed.choice(years_before_last, size=10, replace=False)))\n",
    "test_years = sorted([year for year in years_before_last if year not in train_years] + [2018])\n",
    "train_years, test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(scores, train_years, test_years):\n",
    "    season_scores = scores.loc[scores['event']!='WR']\n",
    "    world_scores = scores.loc[scores['event']=='WR']\n",
    "    \n",
    "    season_train = season_scores.loc[season_scores['year'].isin(train_years)]\n",
    "    world_train = world_scores.loc[world_scores['year'].isin(train_years)]\n",
    "    season_test = season_scores.loc[season_scores['year'].isin(test_years)]\n",
    "    world_test = world_scores.loc[world_scores['year'].isin(test_years)]    \n",
    "    \n",
    "    return season_train, world_train, season_test, world_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1216, 4), (238, 4), (507, 4), (96, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_train, world_train, season_test, world_test = train_test_split(male_scores, train_years, test_years)\n",
    "season_train.shape, world_train.shape, season_test.shape, world_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement kendall tau metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ranking(skater_scores, world_scores):\n",
    "    skater_scores = skater_scores.sort_values(ascending=False)\n",
    "    world_scores = world_scores.sort_values(ascending=False)\n",
    "    skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "    world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "    return skater_ranking, world_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kendall_tau(skater_ranking, world_ranking, verbose=True):\n",
    "    skater_pairs = set(combinations(skater_ranking, 2))\n",
    "    world_pairs = set(combinations(world_ranking, 2))\n",
    "    n_pairs = len(skater_pairs)\n",
    "    n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "    print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "    tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "    return tau "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average skate score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "season_scores = season_train.loc[season_train['year']==year].copy()\n",
    "world_scores = world_train.loc[world_train['year']==year, ['name', 'score']].set_index('name').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        290.5350\n",
       "Javier, FERNANDEZ    285.4925\n",
       "Shoma, UNO           283.7425\n",
       "Nathan, CHEN         281.0050\n",
       "Patrick, CHAN        270.3500\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_avg = season_scores.groupby('name')['score'].mean().sort_values(ascending=False)\n",
    "season_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 234 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ranking, world_ranking = return_ranking(season_avg, world_scores)\n",
    "calculate_kendall_tau(avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result agrees with kendalltau from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.6956521739130435, pvalue=1.9126097800691154e-06)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_numeric_rank = list(range(len(avg_ranking)))\n",
    "world_numeric_rank = [avg_ranking.index(skater) for skater in world_ranking]\n",
    "kendalltau(season_numeric_rank, world_numeric_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE with mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.271546837961868"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison = pd.merge(season_scores, season_avg.to_frame(), left_on='name', right_index=True, suffixes=['', '_avg'])\n",
    "score_comparison['sq_error'] = (score_comparison['score'] - score_comparison['score_avg'])**2\n",
    "np.sqrt(score_comparison['sq_error'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_scores(year, season_scores, world_scores):\n",
    "    yearly_season_scores = season_scores.loc[season_scores['year']==year].copy()\n",
    "    yearly_world_scores = world_scores.loc[world_scores['year']==year, ['name', 'score']].set_index('name').squeeze()\n",
    "    return yearly_season_scores, yearly_world_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.skater_scores = None\n",
    "        self.model_ranking = None\n",
    "        self.world_ranking = None\n",
    "        self.predicted_season_scores = None\n",
    "    \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        squared_errors = (season_scores['score'].values - self.predicted_season_scores)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        return rmse\n",
    "        \n",
    "    def evaluate_kendall_tau(self, world_scores, verbose=True):\n",
    "        def return_ranking(skater_scores, world_scores):\n",
    "            skater_scores = skater_scores.sort_values(ascending=False)\n",
    "            world_scores = world_scores.sort_values(ascending=False)\n",
    "            skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "            world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "            return skater_ranking, world_ranking\n",
    "    \n",
    "        def calculate_kendall_tau(skater_ranking, world_ranking, verbose=verbose):\n",
    "            skater_pairs = set(combinations(skater_ranking, 2))\n",
    "            world_pairs = set(combinations(world_ranking, 2))\n",
    "            n_pairs = len(skater_pairs)\n",
    "            n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "            if verbose:\n",
    "                print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "            tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "            return tau, n_concordant_pairs, n_pairs\n",
    "        \n",
    "        self.model_ranking, self.world_ranking = return_ranking(self.skater_scores, world_scores)\n",
    "        return calculate_kendall_tau(self.model_ranking, self.world_ranking)\n",
    "    \n",
    "    def evaluate_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        taus = []\n",
    "        rmses = []\n",
    "        concordant_pairs = []\n",
    "        n_pairs = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            tau, concordant_pair, n_pair = self.evaluate_kendall_tau(world_scores, verbose=False)\n",
    "            \n",
    "            rmses.append(rmse)\n",
    "            taus.append(tau)\n",
    "            concordant_pairs.append(concordant_pair)\n",
    "            n_pairs.append(n_pair)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses, \n",
    "                             'tau': taus, 'conc': concordant_pairs, 'pairs': n_pairs}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        self.predicted_season_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "    \n",
    "    def fit(self, season_scores):\n",
    "        self.skater_scores = season_scores.groupby('name')['score'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.predict_season_scores(season_scores)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_train_eval = avg.evaluate_over_years(train_years, season_train, world_train)\n",
    "avg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_scores['score_normed'] = season_scores.groupby('event')['score'].transform(lambda score: (score - score.mean()) / score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        1.668135\n",
       "Javier, FERNANDEZ    1.440927\n",
       "Shoma, UNO           1.326910\n",
       "Nathan, CHEN         1.104096\n",
       "Patrick, CHAN        1.090843\n",
       "Name: score_normed, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_normed_avg = season_scores.groupby('name')['score_normed'].mean().sort_values(ascending=False)\n",
    "season_normed_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 222 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6086956521739131"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_avg_ranking, world_ranking = return_ranking(season_normed_avg, world_scores)\n",
    "calculate_kendall_tau(normed_avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormedAverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def predict_season_scores(self, season_scores, event_stds, event_means):\n",
    "        self.predicted_season_scores = (self.skater_scores.loc[season_scores['name']] * event_stds + event_means).values\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        season_scores = season_scores.copy()\n",
    "        event_means = season_scores.groupby('event')['score'].mean().loc[season_scores['event']].values\n",
    "        event_stds = season_scores.groupby('event')['score'].std().loc[season_scores['event']].values\n",
    "        season_scores['score_normed'] = (season_scores['score'] - event_means) / event_stds\n",
    "        \n",
    "        self.skater_scores = season_scores.groupby('name')['score_normed'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        self.predict_season_scores(season_scores, event_stds, event_means)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>14.221490</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>166</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>12.650485</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>12.556444</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>14.067104</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.898410</td>\n",
       "      <td>0.593074</td>\n",
       "      <td>184</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.437599</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>15.373393</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>15.685363</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>177</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>18.328151</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>15.921112</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>222</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  14.221490  0.580952   166    210\n",
       "1  2006  12.650485  0.636364   207    253\n",
       "2  2007  12.556444  0.630435   225    276\n",
       "3  2009  14.067104  0.615942   223    276\n",
       "4  2010  12.898410  0.593074   184    231\n",
       "5  2012  12.437599  0.494071   189    253\n",
       "6  2013  15.373393  0.494071   189    253\n",
       "7  2014  15.685363  0.685714   177    210\n",
       "8  2016  18.328151  0.615942   223    276\n",
       "9  2017  15.921112  0.608696   222    276"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normavg = NormedAverageScore()\n",
    "normavg_train_eval = normavg.evaluate_over_years(train_years, season_train, world_train)\n",
    "normavg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "season_scores = season_train.loc[season_train['year']==year].copy()\n",
    "world_scores = world_train.loc[world_train['year']==year, ['name', 'score']].set_index('name').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "unique_skaters = season_scores['name'].unique()\n",
    "unique_events = season_scores['event'].unique()\n",
    "\n",
    "dummies_skater_count = len(unique_skaters) - 1\n",
    "dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "dropped_event = list(set(unique_events) - set(dummies_events))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "        -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "        -45.88750626,  -35.41149857])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dummies.values\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "y = season_scores['score'].values\n",
    "coefs_linear = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "coefs_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_rmse = np.sqrt(np.mean((y - X @ coefs_linear)**2))\n",
    "linear_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "         -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "         -45.88750626,  -35.41149857]), 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, y)\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y, X @ lin.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropped baseline skater and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Model):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.event_scores = None\n",
    "        self.baseline = None\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ y)\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "        unique_skaters = season_scores['name'].unique()\n",
    "        unique_events = season_scores['event'].unique()\n",
    "        \n",
    "        dummies_skater_count = len(unique_skaters) - 1\n",
    "        dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "        dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "        dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "        dropped_event = list(set(unique_events) - set(dummies_events))[0]\n",
    "\n",
    "        X = dummies.values\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        y = season_scores['score'].values\n",
    "        coefs = self.find_coefs(X, y)\n",
    "\n",
    "        self.baseline = coefs[0]    \n",
    "        self.skater_scores = pd.Series(coefs[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "        self.event_scores = pd.Series(coefs[dummies_skater_count+1:], index=dummies_events)\n",
    "        self.skater_scores[dropped_skater] = 0\n",
    "        self.event_scores[dropped_event] = 0\n",
    "        \n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(ascending=False, inplace=True)        \n",
    "        \n",
    "        self.predict_season_scores(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.555327</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.883763</td>\n",
       "      <td>0.620553</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.578146</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.110917</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>219</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.798364</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>196</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.144647</td>\n",
       "      <td>0.541502</td>\n",
       "      <td>195</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.047367</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.781486</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>190</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.053367</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.838700</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.555327  0.666667   175    210\n",
       "1  2006   7.883763  0.620553   205    253\n",
       "2  2007   7.578146  0.601449   221    276\n",
       "3  2009   8.110917  0.586957   219    276\n",
       "4  2010   9.798364  0.696970   196    231\n",
       "5  2012   8.144647  0.541502   195    253\n",
       "6  2013   9.047367  0.691700   214    253\n",
       "7  2014   8.781486  0.809524   190    210\n",
       "8  2016  11.053367  0.673913   231    276\n",
       "9  2017   8.838700  0.731884   239    276"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear()\n",
    "linear_train_eval = linear.evaluate_over_years(train_years, season_train, world_train)\n",
    "linear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.662111801242236"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.779208324854647 0.662111801242236\n",
      "0.001 8.782755125399937 0.6619499341238472\n",
      "0.01 8.925173433616132 0.6596894409937888\n",
      "0.1 9.788140496081605 0.6537982307547525\n",
      "1 15.206034467688387 0.637331074722379\n",
      "10 27.042844923858063 0.6193073593073594\n",
      "100 32.34814733209342 0.6250574063617542\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    linear = Linear(lambda_reg=lambda_reg)\n",
    "    linear_train_eval = linear.evaluate_over_years(train_years, season_train, world_train)\n",
    "    print(lambda_reg, linear_train_eval['rmse'].mean(), linear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "       -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_log_linear = np.linalg.inv(X.T @ X) @ (X.T @ np.log(y))\n",
    "coefs_log_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_linear_rmse = np.exp(np.sqrt(np.mean((np.log(y) - X @ coefs_log_linear)**2)))\n",
    "log_linear_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_log_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_log_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "skater_scores = np.exp(skater_scores)\n",
    "event_scores = np.exp(event_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  1.154228\n",
       "Nathan, CHEN                   1.110905\n",
       "Javier, FERNANDEZ              1.108103\n",
       "Shoma, UNO                     1.105957\n",
       "Patrick, CHAN                  1.062009\n",
       "Denis, TEN                     1.059121\n",
       "Boyang, JIN                    1.014664\n",
       "Adam, RIPPON                   1.000000\n",
       "Jason, BROWN                   0.953747\n",
       "Sergei, VORONOV                0.947786\n",
       "Alexei, BYCHENKO               0.937530\n",
       "Mikhail, KOLYADA               0.933023\n",
       "Takahito, MURA                 0.932946\n",
       "Max, AARON                     0.928603\n",
       "Kevin, REYNOLDS                0.912023\n",
       "Maxim, KOVTUN                  0.911407\n",
       "Misha, GE                      0.906351\n",
       "Keiji, TANAKA                  0.905789\n",
       "Nam, NGUYEN                    0.898441\n",
       "Alexander, PETROV              0.892819\n",
       "Jorik, HENDRICKX               0.891376\n",
       "Moris, KVITELASHVILI           0.880480\n",
       "Timothy, DOLENSKY              0.877638\n",
       "Han, YAN                       0.875485\n",
       "Gordei, GORSHKOV               0.869104\n",
       "Daniel, SAMOHIN                0.867256\n",
       "Chafik, BESSEGHIER             0.865572\n",
       "Artur, DMITRIEV                0.860806\n",
       "Deniss, VASILJEVS              0.856720\n",
       "Alexander, SAMARIN             0.853385\n",
       "                                 ...   \n",
       "Michal, BREZINA                0.841853\n",
       "Elladj, BALDE                  0.835828\n",
       "Paul, FENTZ                    0.834829\n",
       "Grant, HOCHSTEIN               0.831686\n",
       "Brendan, KERRY                 0.822836\n",
       "Michael Christian, MARTINEZ    0.815368\n",
       "Ross, MINER                    0.807469\n",
       "Alexander, MAJOROV             0.775878\n",
       "Julian Zhi Jie, YEE            0.771658\n",
       "Ivan, RIGHINI                  0.753486\n",
       "Ivan, PAVLOV                   0.749886\n",
       "Sihyeong, LEE                  0.745196\n",
       "Jinseo, KIM                    0.742645\n",
       "Kevin, AYMOZ                   0.737319\n",
       "Graham, NEWBERRY               0.732107\n",
       "Stephane, WALKER               0.727227\n",
       "Javier, RAYA                   0.722792\n",
       "June Hyoung, LEE               0.714204\n",
       "Maurizio, ZANDRON              0.689007\n",
       "Jiri, BELOHRADSKY              0.671338\n",
       "Slavik, HAYRAPETYAN            0.668233\n",
       "Daniel Albert, NAURITS         0.650934\n",
       "Chih-I, TSAO                   0.645860\n",
       "Andrew, DODDS                  0.616999\n",
       "Mark, WEBSTER                  0.609308\n",
       "Valtter, VIRTANEN              0.606540\n",
       "Sondre, ODDVOLL BOE            0.601957\n",
       "Leslie, IP                     0.558707\n",
       "Kai Xiang, CHEW                0.527181\n",
       "Micah, TANG                    0.517015\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skater_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "        -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472]), 0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, np.log(y))\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.sqrt(mean_squared_error(np.log(y), X @ lin.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Kendall's Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLinear(Linear):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ np.log(y))\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.log_predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        self.predicted_season_scores = np.exp(self.log_predicted_season_scores)\n",
    "        \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        log_squared_errors = (np.log(season_scores['score'].values) - self.log_predicted_season_scores)**2\n",
    "        log_rmse = np.sqrt(log_squared_errors.mean())\n",
    "        rmse = np.exp(log_rmse)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>1.051008</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.045100</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>1.042015</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1.042605</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>216</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.050437</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.040119</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>193</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.041869</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>213</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>1.040164</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.048652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      rmse       tau  conc  pairs\n",
       "0  2005  1.051008  0.666667   175    210\n",
       "1  2006  1.045100  0.636364   207    253\n",
       "2  2007  1.042015  0.601449   221    276\n",
       "3  2009  1.042605  0.565217   216    276\n",
       "4  2010  1.050437  0.714286   198    231\n",
       "5  2012  1.040119  0.525692   193    253\n",
       "6  2013  1.041869  0.683794   213    253\n",
       "7  2014  1.040164  0.828571   192    210\n",
       "8  2016  1.048652  0.673913   231    276\n",
       "9  2017  1.037668  0.731884   239    276"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear = LogLinear()\n",
    "loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_train, world_train)\n",
    "loglinear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627837380011293"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.evaluate_over_years(train_years, season_train, world_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.043963617896676 0.6627837380011293\n",
      "0.001 1.043998390360219 0.6618520609824958\n",
      "0.01 1.0453133728174064 0.653425559947299\n",
      "0.1 1.0518538623368006 0.6394089968003012\n",
      "1 1.087499139738013 0.6379691323169585\n",
      "10 1.162036606713829 0.6258008658008658\n",
      "100 1.1945282438818492 0.6286598908338039\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    loglinear = LogLinear(lambda_reg=lambda_reg)\n",
    "    loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_train, world_train)\n",
    "    print(lambda_reg, loglinear_train_eval['rmse'].mean(), loglinear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "skater_names = list(season_table.index)\n",
    "event_names = list(season_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 9)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scores = season_table.values\n",
    "skater_scores = np.full(len(skater_names), 0.5)\n",
    "event_scores = np.full(len(event_names), 0.5)\n",
    "bias = 0.5\n",
    "\n",
    "alpha = 0.0001\n",
    "rmses = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    diff = np.outer(skater_scores, event_scores) + bias - true_scores\n",
    "    skater_gradients = np.nansum(diff * event_scores, axis=1)\n",
    "    event_gradients = np.nansum(diff.T * skater_scores, axis=1)\n",
    "    bias_gradient = np.nansum(diff)\n",
    "    \n",
    "    event_scores = event_scores - alpha * event_gradients\n",
    "    skater_scores = skater_scores - alpha * skater_gradients\n",
    "    bias = bias - alpha * bias_gradient\n",
    "    rmse = np.sqrt(np.nanmean(diff**2))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.85743476115872"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f322b9e0eb8>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  11.548237\n",
       "Nathan, CHEN                   10.957354\n",
       "Javier, FERNANDEZ              10.861625\n",
       "Shoma, UNO                     10.849096\n",
       "Patrick, CHAN                  10.321209\n",
       "Denis, TEN                     10.279188\n",
       "Boyang, JIN                     9.726375\n",
       "Adam, RIPPON                    9.534382\n",
       "Jason, BROWN                    8.960669\n",
       "Sergei, VORONOV                 8.834118\n",
       "Takahito, MURA                  8.716277\n",
       "Alexei, BYCHENKO                8.634810\n",
       "Mikhail, KOLYADA                8.593187\n",
       "Max, AARON                      8.527820\n",
       "Maxim, KOVTUN                   8.420850\n",
       "Kevin, REYNOLDS                 8.402344\n",
       "Misha, GE                       8.335658\n",
       "Keiji, TANAKA                   8.223416\n",
       "Nam, NGUYEN                     8.211308\n",
       "Alexander, PETROV               8.143620\n",
       "Jorik, HENDRICKX                8.117258\n",
       "Moris, KVITELASHVILI            7.974540\n",
       "Timothy, DOLENSKY               7.955134\n",
       "Han, YAN                        7.947754\n",
       "Daniel, SAMOHIN                 7.801058\n",
       "Chafik, BESSEGHIER              7.735092\n",
       "Gordei, GORSHKOV                7.735000\n",
       "Artur, DMITRIEV                 7.664270\n",
       "Alexander, SAMARIN              7.630675\n",
       "Deniss, VASILJEVS               7.608608\n",
       "                                 ...    \n",
       "Ryuju, HINO                     7.416069\n",
       "Grant, HOCHSTEIN                7.396732\n",
       "Paul, FENTZ                     7.395176\n",
       "Elladj, BALDE                   7.344306\n",
       "Brendan, KERRY                  7.257003\n",
       "Michael Christian, MARTINEZ     7.155151\n",
       "Ross, MINER                     7.048462\n",
       "Alexander, MAJOROV              6.624793\n",
       "Julian Zhi Jie, YEE             6.592306\n",
       "Ivan, RIGHINI                   6.363354\n",
       "Ivan, PAVLOV                    6.317138\n",
       "Sihyeong, LEE                   6.251560\n",
       "Jinseo, KIM                     6.218711\n",
       "Kevin, AYMOZ                    6.157638\n",
       "Graham, NEWBERRY                6.091492\n",
       "Stephane, WALKER                6.029568\n",
       "Javier, RAYA                    5.973273\n",
       "June Hyoung, LEE                5.852470\n",
       "Maurizio, ZANDRON               5.544498\n",
       "Jiri, BELOHRADSKY               5.320258\n",
       "Slavik, HAYRAPETYAN             5.280852\n",
       "Daniel Albert, NAURITS          5.061304\n",
       "Chih-I, TSAO                    4.972412\n",
       "Andrew, DODDS                   4.600778\n",
       "Mark, WEBSTER                   4.501741\n",
       "Valtter, VIRTANEN               4.497891\n",
       "Sondre, ODDVOLL BOE             4.439720\n",
       "Leslie, IP                      3.850155\n",
       "Kai Xiang, CHEW                 3.444201\n",
       "Micah, TANG                     3.313295\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_scores = pd.Series(skater_scores, index=skater_names)\n",
    "hybrid_scores.sort_values(ascending=False, inplace=True)\n",
    "hybrid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_ranking, world_ranking = return_ranking(hybrid_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 238 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7246376811594203"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(hybrid_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(Linear):\n",
    "    def __init__(self, alpha, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.predicted_season_scores = broadcasted_skater_scores * broadcasted_event_scores + self.baseline\n",
    "        \n",
    "    def fit(self, season_scores, n_iter):\n",
    "        season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "        skater_names = list(season_table.index)\n",
    "        event_names = list(season_table.columns)\n",
    "\n",
    "        true_scores = season_table.values\n",
    "        self.skater_scores = np.full(len(skater_names), 0.5)\n",
    "        self.event_scores = np.full(len(event_names), 0.5)\n",
    "        self.baseline = 0.5\n",
    "\n",
    "        self.rmses = []\n",
    "\n",
    "        for _ in range(n_iter):\n",
    "            diff = np.outer(self.skater_scores, self.event_scores) + self.baseline - true_scores\n",
    "            baseline_gradient = np.nansum(diff)\n",
    "            skater_gradients = np.nansum(diff * self.event_scores, axis=1) + self.lambda_reg * self.skater_scores\n",
    "            event_gradients = np.nansum(diff.T * self.skater_scores, axis=1) + self.lambda_reg * self.event_scores            \n",
    "            \n",
    "            self.baseline = self.baseline - self.alpha * baseline_gradient\n",
    "            self.skater_scores = self.skater_scores - self.alpha * skater_gradients\n",
    "            self.event_scores = self.event_scores - self.alpha * event_gradients\n",
    "            rmse = np.sqrt(np.nanmean(diff**2))\n",
    "            self.rmses.append(rmse)\n",
    "            \n",
    "        self.skater_scores = pd.Series(self.skater_scores, index=skater_names)\n",
    "        self.event_scores = pd.Series(self.event_scores, index=event_names)\n",
    "        \n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(ascending=False, inplace=True)        \n",
    "        \n",
    "        self.predict_season_scores(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.fit(season_scores, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  11.548237\n",
       "Nathan, CHEN                   10.957354\n",
       "Javier, FERNANDEZ              10.861625\n",
       "Shoma, UNO                     10.849096\n",
       "Patrick, CHAN                  10.321209\n",
       "Denis, TEN                     10.279188\n",
       "Boyang, JIN                     9.726375\n",
       "Adam, RIPPON                    9.534382\n",
       "Jason, BROWN                    8.960669\n",
       "Sergei, VORONOV                 8.834118\n",
       "Takahito, MURA                  8.716277\n",
       "Alexei, BYCHENKO                8.634810\n",
       "Mikhail, KOLYADA                8.593187\n",
       "Max, AARON                      8.527820\n",
       "Maxim, KOVTUN                   8.420850\n",
       "Kevin, REYNOLDS                 8.402344\n",
       "Misha, GE                       8.335658\n",
       "Keiji, TANAKA                   8.223416\n",
       "Nam, NGUYEN                     8.211308\n",
       "Alexander, PETROV               8.143620\n",
       "Jorik, HENDRICKX                8.117258\n",
       "Moris, KVITELASHVILI            7.974540\n",
       "Timothy, DOLENSKY               7.955134\n",
       "Han, YAN                        7.947754\n",
       "Daniel, SAMOHIN                 7.801058\n",
       "Chafik, BESSEGHIER              7.735092\n",
       "Gordei, GORSHKOV                7.735000\n",
       "Artur, DMITRIEV                 7.664270\n",
       "Alexander, SAMARIN              7.630675\n",
       "Deniss, VASILJEVS               7.608608\n",
       "                                 ...    \n",
       "Ryuju, HINO                     7.416069\n",
       "Grant, HOCHSTEIN                7.396732\n",
       "Paul, FENTZ                     7.395176\n",
       "Elladj, BALDE                   7.344306\n",
       "Brendan, KERRY                  7.257003\n",
       "Michael Christian, MARTINEZ     7.155151\n",
       "Ross, MINER                     7.048462\n",
       "Alexander, MAJOROV              6.624793\n",
       "Julian Zhi Jie, YEE             6.592306\n",
       "Ivan, RIGHINI                   6.363354\n",
       "Ivan, PAVLOV                    6.317138\n",
       "Sihyeong, LEE                   6.251560\n",
       "Jinseo, KIM                     6.218711\n",
       "Kevin, AYMOZ                    6.157638\n",
       "Graham, NEWBERRY                6.091492\n",
       "Stephane, WALKER                6.029568\n",
       "Javier, RAYA                    5.973273\n",
       "June Hyoung, LEE                5.852470\n",
       "Maurizio, ZANDRON               5.544498\n",
       "Jiri, BELOHRADSKY               5.320258\n",
       "Slavik, HAYRAPETYAN             5.280852\n",
       "Daniel Albert, NAURITS          5.061304\n",
       "Chih-I, TSAO                    4.972412\n",
       "Andrew, DODDS                   4.600778\n",
       "Mark, WEBSTER                   4.501741\n",
       "Valtter, VIRTANEN               4.497891\n",
       "Sondre, ODDVOLL BOE             4.439720\n",
       "Leslie, IP                      3.850155\n",
       "Kai Xiang, CHEW                 3.444201\n",
       "Micah, TANG                     3.313295\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.skater_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EU    21.316523\n",
       "4C    20.396416\n",
       "RU    20.077497\n",
       "CN    20.013259\n",
       "US    19.901545\n",
       "FR    19.558890\n",
       "FN    19.056336\n",
       "CA    18.818920\n",
       "JP    18.734913\n",
       "dtype: float64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.event_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 238 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7246376811594203, 238, 276)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.evaluate_kendall_tau(world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.85743475871782"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.evaluate_rmse(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.617690</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>174</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.942200</td>\n",
       "      <td>0.612648</td>\n",
       "      <td>204</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.607107</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.179645</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.742164</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>195</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.293977</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>198</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>8.921183</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.794281</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>10.983638</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.857435</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>238</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.617690  0.657143   174    210\n",
       "1  2006   7.942200  0.612648   204    253\n",
       "2  2007   7.607107  0.630435   225    276\n",
       "3  2009   8.179645  0.601449   221    276\n",
       "4  2010   9.742164  0.688312   195    231\n",
       "5  2012   8.293977  0.565217   198    253\n",
       "6  2013   8.921183  0.691700   214    253\n",
       "7  2014   8.794281  0.828571   192    210\n",
       "8  2016  10.983638  0.695652   234    276\n",
       "9  2017   8.857435  0.724638   238    276"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid = Hybrid(alpha=0.0001)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, n_iter=1000)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.793932072159187, 8.779208324854647, 1.043963617896676, 10.087526233651136)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_train_eval['rmse'].mean(), linear_train_eval['rmse'].mean(), loglinear_train_eval['rmse'].mean(), avg_train_eval['rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6695765104460756, 0.662111801242236, 0.6627837380011293, 0.6705326557500471)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_train_eval['tau'].mean(), linear_train_eval['tau'].mean(), loglinear_train_eval['tau'].mean(), avg_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.784971958845214 0.6689177489177489\n",
      "0.1 8.785006452540717 0.6697082627517409\n",
      "1 8.78840266993188 0.6729757199322416\n",
      "2 8.798615740372517 0.6715264445699227\n",
      "5 8.868634191409939 0.6670882740447956\n",
      "10 9.107376558094924 0.6667739506869942\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.1, 1, 2, 5, 10]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.0001)\n",
    "    hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, n_iter=1000)\n",
    "    print(lambda_reg, hybrid_train_eval['rmse'].mean(), hybrid_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.760431792298688 0.5975672877846792\n",
      "0.1 8.760463967311871 0.5997317899491812\n",
      "1 8.763637239308693 0.6015433841520799\n",
      "2 8.773195602514855 0.6011904761904763\n",
      "5 8.838952915841109 0.6055194805194806\n",
      "10 9.064275282147968 0.6030020703933747\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.1, 1, 2, 5, 10]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.0001)\n",
    "    hybrid_test_eval = hybrid.evaluate_over_years(test_years, season_test, world_test, n_iter=1000)\n",
    "    print(lambda_reg, hybrid_test_eval['rmse'].mean(), hybrid_test_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6094955768868812"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_test_eval = avg.evaluate_over_years(test_years, season_test, world_test)\n",
    "avg_test_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-0281707b6d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlinear_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_linear_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mall_scores_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mall_scores_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_scores' is not defined"
     ]
    }
   ],
   "source": [
    "all_scores = pd.concat([linear_scores, log_linear_scores, hybrid_scores], axis=1, sort=True)\n",
    "all_scores = all_scores.reindex(world_scores.index).values\n",
    "all_scores_mean = all_scores.mean(axis=0)\n",
    "all_scores_std = all_scores.std(axis=0)\n",
    "all_scores = (all_scores - all_scores_mean) / all_scores_std\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(all_scores, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_scores[:, 1], all_scores[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_status = np.full(len(score_diffs), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = BatchLogistic(theta=[0.5, 0.5, 0.5], alpha=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(score_diffs, pairwise_status, n_iter=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(log.avg_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_scores = pd.Series(all_scores @ log.theta, index=world_scores.index).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ranking, world_ranking = return_ranking(combined_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_kendall_tau(combined_ranking, world_ranking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
