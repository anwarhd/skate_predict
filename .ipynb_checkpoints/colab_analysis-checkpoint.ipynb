{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6vdDE5QK42A"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2QG8S_wK42G"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "plt.style.use('seaborn')\n",
    "rc('text', usetex=False)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-rGwO53K42L"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D38PX8wbLEXu"
   },
   "outputs": [],
   "source": [
    "class BatchLogistic:\n",
    "    def __init__(self, theta, alpha, lambda_reg=0):\n",
    "        # Initialize model object with given theta, alpha (learning rate),\n",
    "        # and lambda_reg (regularization hyperparameter)\n",
    "        self.theta = np.array(theta)\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "    def sigmoid(self, X, theta):\n",
    "        # Sigmoid function to calculate probability of weight gain from feature matrix X and theta vector\n",
    "        return 1 / (1 + np.exp(-X @ theta))\n",
    "    \n",
    "    def fit(self, X, y, n_iter):\n",
    "        self.avg_log_likelihoods = []\n",
    "        self.thetas = []\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            # Record theta for every iteration\n",
    "            self.thetas.append(self.theta)\n",
    "            \n",
    "            prob = self.sigmoid(X, self.theta) # Step 1      \n",
    "            # Record average log-likelihood for every iteration\n",
    "            if np.all(prob != 0) or np.all(prob != 1):\n",
    "                self.avg_log_likelihood = (y @ np.log(prob) + (1 - y) @ np.log(1 - prob)) / len(y)\n",
    "                self.avg_log_likelihoods.append(self.avg_log_likelihood)\n",
    "            \n",
    "            # Calculate regularization term for ridge regression\n",
    "            reg_term = self.lambda_reg * self.theta\n",
    "            # First feature (intercept) is not regularized\n",
    "            reg_term[0] = 0\n",
    "            \n",
    "            self.gradient = (y - prob) @ X - reg_term # Step 2, note the extra reg_term subtracted at the end\n",
    "            self.theta = self.theta + self.alpha * self.gradient # Step 3\n",
    "        # Record difference in average log-likelihood for the last iteration\n",
    "        self.last_avg_log_likelihood_diff = self.avg_log_likelihoods[-1] - self.avg_log_likelihoods[-2]\n",
    "        self.thetas = np.array(self.thetas)\n",
    "            \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        # Return predicted labels when using trained model on X feature matrix\n",
    "        return (self.sigmoid(X, self.theta) > threshold).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Return predicted probability of weight gain using trained model on X feature matrix\n",
    "        return self.sigmoid(X, self.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpVXtGLxK42Q"
   },
   "source": [
    "## Import scores from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hS7gVpsQK42R"
   },
   "outputs": [],
   "source": [
    "male_scores = pd.read_csv('https://raw.githubusercontent.com/dknguyengit/skate_predict/master/scores/trimmed_male.csv')\n",
    "female_scores = pd.read_csv('https://raw.githubusercontent.com/dknguyengit/skate_predict/master/scores/trimmed_female.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WMXvLqyK42W"
   },
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WsZIQ8ndK42Y",
    "outputId": "a6343a16-1094-41be-9e88-db3f17a306fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2005, 2006, 2007, 2009, 2010, 2012, 2013, 2014, 2016, 2017],\n",
       " [2008, 2011, 2015, 2018])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_before_last = range(2005, 2018)\n",
    "year_seed = np.random.RandomState(seed=42)\n",
    "train_years = sorted(list(year_seed.choice(years_before_last, size=10, replace=False)))\n",
    "test_years = sorted([year for year in years_before_last if year not in train_years] + [2018])\n",
    "train_years, test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_q7dyBXjVhWg"
   },
   "outputs": [],
   "source": [
    "season_male = male_scores.loc[male_scores['event']!='WR']\n",
    "world_male = male_scores.loc[male_scores['event']=='WR']\n",
    "season_female = female_scores.loc[female_scores['event']!='WR']\n",
    "world_female = female_scores.loc[female_scores['event']=='WR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MEuxURVK42q"
   },
   "source": [
    "## Implement kendall tau metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg8SXIIQK42s"
   },
   "outputs": [],
   "source": [
    "def return_ranking(skater_scores, world_scores):\n",
    "    skater_scores = skater_scores.sort_values(ascending=False)\n",
    "    world_scores = world_scores.sort_values(ascending=False)\n",
    "    skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "    world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "    return skater_ranking, world_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZrH9HhzK42y"
   },
   "outputs": [],
   "source": [
    "def calculate_kendall_tau(skater_ranking, world_ranking, verbose=True):\n",
    "    skater_pairs = set(combinations(skater_ranking, 2))\n",
    "    world_pairs = set(combinations(world_ranking, 2))\n",
    "    n_pairs = len(skater_pairs)\n",
    "    n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "    if verbose:\n",
    "      print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "    tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "    return tau "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_M0gGlAvK427"
   },
   "source": [
    "## Average skate score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsP5b9rHK428"
   },
   "outputs": [],
   "source": [
    "def get_yearly_scores(year, season_scores, world_scores):\n",
    "    yearly_season_scores = season_scores.loc[season_scores['year']==year].copy()\n",
    "    yearly_world_scores = world_scores.loc[world_scores['year']==year, ['name', 'score']].set_index('name').squeeze()\n",
    "    return yearly_season_scores, yearly_world_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dna_GOVgK43E",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_scores, world_scores = get_yearly_scores(2017, season_male, world_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "_iVebe2UK43M",
    "outputId": "33cd486b-fcac-49b4-9a2c-d9cbb6abef13",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        290.5350\n",
       "Javier, FERNANDEZ    285.4925\n",
       "Shoma, UNO           283.7425\n",
       "Nathan, CHEN         281.0050\n",
       "Patrick, CHAN        270.3500\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_avg = season_scores.groupby('name')['score'].mean().sort_values(ascending=False)\n",
    "season_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3ZVP4keXK43R",
    "outputId": "7cf4b18d-d329-4b0f-9476-c045ef6bf18f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 234 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ranking, world_ranking = return_ranking(season_avg, world_scores)\n",
    "calculate_kendall_tau(avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESDfYSHmK43W"
   },
   "source": [
    "Result agrees with kendalltau from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4YmXqEQTK43Y",
    "outputId": "e3ed08b8-53e3-4e1c-ce73-2c6cb14bed7d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.6956521739130435, pvalue=1.9126097800691154e-06)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_numeric_rank = list(range(len(avg_ranking)))\n",
    "world_numeric_rank = [avg_ranking.index(skater) for skater in world_ranking]\n",
    "kendalltau(season_numeric_rank, world_numeric_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WToqULyGK43f"
   },
   "source": [
    "RMSE with mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KPennikYK43g",
    "outputId": "1acc5d66-034f-479b-ee03-cfc5c06e3eac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.271546837961868"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison = pd.merge(season_scores, season_avg.to_frame(), left_on='name', right_index=True, suffixes=['', '_avg'])\n",
    "score_comparison['sq_error'] = (score_comparison['score'] - score_comparison['score_avg'])**2\n",
    "np.sqrt(score_comparison['sq_error'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz5J6WqHK43m"
   },
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iS5BNC6HK43o"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.skater_scores = None\n",
    "        self.model_ranking = None\n",
    "        self.world_ranking = None\n",
    "        self.predicted_season_scores = None\n",
    "    \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        squared_errors = (season_scores['score'].values - self.predicted_season_scores)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        return rmse\n",
    "        \n",
    "    def evaluate_kendall_tau(self, world_scores, verbose=True):\n",
    "        def return_ranking(skater_scores, world_scores):\n",
    "            skater_scores = skater_scores.sort_values(ascending=False)\n",
    "            world_scores = world_scores.sort_values(ascending=False)\n",
    "            skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "            world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "            return skater_ranking, world_ranking\n",
    "    \n",
    "        def calculate_kendall_tau(skater_ranking, world_ranking, verbose=verbose):\n",
    "            skater_pairs = set(combinations(skater_ranking, 2))\n",
    "            world_pairs = set(combinations(world_ranking, 2))\n",
    "            n_pairs = len(skater_pairs)\n",
    "            n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "            if verbose:\n",
    "                print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "            tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "            return tau, n_concordant_pairs, n_pairs\n",
    "        \n",
    "        skater_scores = self.skater_scores.squeeze()\n",
    "        self.model_ranking, self.world_ranking = return_ranking(skater_scores, world_scores)\n",
    "        return calculate_kendall_tau(self.model_ranking, self.world_ranking)\n",
    "    \n",
    "    def evaluate_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        taus = []\n",
    "        rmses = []\n",
    "        concordant_pairs = []\n",
    "        n_pairs = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            tau, concordant_pair, n_pair = self.evaluate_kendall_tau(world_scores, verbose=False)\n",
    "            \n",
    "            rmses.append(rmse)\n",
    "            taus.append(tau)\n",
    "            concordant_pairs.append(concordant_pair)\n",
    "            n_pairs.append(n_pair)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses, \n",
    "                             'tau': taus, 'conc': concordant_pairs, 'pairs': n_pairs}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Edog7e3DK43s"
   },
   "outputs": [],
   "source": [
    "class AverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        self.predicted_season_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "    \n",
    "    def fit(self, season_scores):\n",
    "        self.skater_scores = season_scores.groupby('name')['score'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.predict_season_scores(season_scores)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "7D-8RIF3K43x",
    "outputId": "e97c2094-5ec2-490b-e861-340cd0539549"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_train_eval = avg.evaluate_over_years(train_years, season_male, world_male)\n",
    "avg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3mBwvLWMK434"
   },
   "source": [
    "## Normalized mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwajLn1VK435",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_scores['score_normed'] = season_scores.groupby('event')['score'].transform(lambda score: (score - score.mean()) / score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "yd85c7_UK439",
    "outputId": "2a8fd46f-cd06-40d0-e059-5835ec3266f8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        1.668135\n",
       "Javier, FERNANDEZ    1.440927\n",
       "Shoma, UNO           1.326910\n",
       "Nathan, CHEN         1.104096\n",
       "Patrick, CHAN        1.090843\n",
       "Name: score_normed, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_normed_avg = season_scores.groupby('name')['score_normed'].mean().sort_values(ascending=False)\n",
    "season_normed_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Hn42yxYIK44B",
    "outputId": "45cdc564-9ecb-45d1-d433-b5f9bdab9bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 222 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6086956521739131"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_avg_ranking, world_ranking = return_ranking(season_normed_avg, world_scores)\n",
    "calculate_kendall_tau(normed_avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_aFu5B5K44G"
   },
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1PjjYBaK44I"
   },
   "outputs": [],
   "source": [
    "class NormedAverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def predict_season_scores(self, season_scores, event_stds, event_means):\n",
    "        self.predicted_season_scores = (self.skater_scores.loc[season_scores['name']] * event_stds + event_means).values\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        season_scores = season_scores.copy()\n",
    "        event_means = season_scores.groupby('event')['score'].mean().loc[season_scores['event']].values\n",
    "        event_stds = season_scores.groupby('event')['score'].std().loc[season_scores['event']].values\n",
    "        season_scores['score_normed'] = (season_scores['score'] - event_means) / event_stds\n",
    "        \n",
    "        self.skater_scores = season_scores.groupby('name')['score_normed'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        self.predict_season_scores(season_scores, event_stds, event_means)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "LfbuTk4eK44T",
    "outputId": "dc15a903-bc9b-4cfa-c633-d52fd5cef791"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>14.221490</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>166</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>12.650485</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>12.556444</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>14.067104</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.898410</td>\n",
       "      <td>0.593074</td>\n",
       "      <td>184</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.437599</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>15.373393</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>15.685363</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>177</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>18.328151</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>15.921112</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>222</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  14.221490  0.580952   166    210\n",
       "1  2006  12.650485  0.636364   207    253\n",
       "2  2007  12.556444  0.630435   225    276\n",
       "3  2009  14.067104  0.615942   223    276\n",
       "4  2010  12.898410  0.593074   184    231\n",
       "5  2012  12.437599  0.494071   189    253\n",
       "6  2013  15.373393  0.494071   189    253\n",
       "7  2014  15.685363  0.685714   177    210\n",
       "8  2016  18.328151  0.615942   223    276\n",
       "9  2017  15.921112  0.608696   222    276"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normavg = NormedAverageScore()\n",
    "normavg_train_eval = normavg.evaluate_over_years(train_years, season_male, world_male)\n",
    "normavg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcn6ISzlK44Y"
   },
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MwEEKh0K44c"
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "unique_skaters = season_scores['name'].unique()\n",
    "unique_events = season_scores['event'].unique()\n",
    "\n",
    "dummies_skater_count = len(unique_skaters) - 1\n",
    "dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "dropped_event = list(set(unique_events) - set(dummies_events))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "R7UkEp3OK44g",
    "outputId": "f8af5b8e-b2f4-4263-a2da-7d3d8cf2c119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "        -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "        -45.88750626,  -35.41149857])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dummies.values\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "y = season_scores['score'].values\n",
    "coefs_linear = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "coefs_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IWmwN-JSK44m",
    "outputId": "49d39a7e-5afc-4584-eba5-028a1546bc80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_rmse = np.sqrt(np.mean((y - X @ coefs_linear)**2))\n",
    "linear_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdD6OGNTK44r"
   },
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "-1mlAzzVK44w",
    "outputId": "851e4f71-79f6-4710-f1bc-4c646a07db49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "         -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "         -45.88750626,  -35.41149857]), 0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, y)\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qHJBtNBIK440",
    "outputId": "67b0fe1b-312d-48ff-e948-f1e5ed32fbfc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y, X @ lin.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Auz8Zhx6K45A"
   },
   "source": [
    "Add dropped baseline skater and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwWRI32HK45B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRw2lbS1K45F"
   },
   "outputs": [],
   "source": [
    "linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "UHBg1kSRK45I",
    "outputId": "4df09f3c-69ee-4019-f36a-917a757a83f2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbtqgnKTK45N"
   },
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QayYkKoNK45N"
   },
   "outputs": [],
   "source": [
    "class Linear(Model):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.event_scores = None\n",
    "        self.baseline = None\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ y)\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "        unique_skaters = season_scores['name'].unique()\n",
    "        unique_events = season_scores['event'].unique()\n",
    "        \n",
    "        dummies_skater_count = len(unique_skaters) - 1\n",
    "        dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "        dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "        dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "        dropped_event = list(set(unique_events) - set(dummies_events))[0]\n",
    "\n",
    "        X = dummies.values\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        y = season_scores['score'].values\n",
    "        coefs = self.find_coefs(X, y)\n",
    "\n",
    "        self.baseline = coefs[0]    \n",
    "        self.skater_scores = pd.Series(coefs[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "        self.event_scores = pd.Series(coefs[dummies_skater_count+1:], index=dummies_events)\n",
    "        self.skater_scores[dropped_skater] = 0\n",
    "        self.event_scores[dropped_event] = 0\n",
    "        \n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(ascending=False, inplace=True)        \n",
    "        \n",
    "        self.predict_season_scores(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "Yg91CtcUK45S",
    "outputId": "055c653a-d697-463c-93a2-d13adf2be7b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.555327</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.883763</td>\n",
       "      <td>0.620553</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.578146</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.110917</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>219</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.798364</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>196</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.144647</td>\n",
       "      <td>0.541502</td>\n",
       "      <td>195</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.047367</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.781486</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>190</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.053367</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.838700</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.555327  0.666667   175    210\n",
       "1  2006   7.883763  0.620553   205    253\n",
       "2  2007   7.578146  0.601449   221    276\n",
       "3  2009   8.110917  0.586957   219    276\n",
       "4  2010   9.798364  0.696970   196    231\n",
       "5  2012   8.144647  0.541502   195    253\n",
       "6  2013   9.047367  0.691700   214    253\n",
       "7  2014   8.781486  0.809524   190    210\n",
       "8  2016  11.053367  0.673913   231    276\n",
       "9  2017   8.838700  0.731884   239    276"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear()\n",
    "linear_train_eval = linear.evaluate_over_years(train_years, season_male, world_male)\n",
    "linear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KUEpFwHGK45Z",
    "outputId": "4c5634b4-a6b5-4338-8d5e-df2f24d539b2",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.662111801242236"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "BvdNHpTNK45l",
    "outputId": "9783466f-ddb3-4328-a8dd-752142132fce",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.779208324854647 0.662111801242236\n",
      "0.001 8.782755125399937 0.6619499341238472\n",
      "0.01 8.925173433616132 0.6596894409937888\n",
      "0.1 9.788140496081605 0.6537982307547525\n",
      "1 15.206034467688387 0.637331074722379\n",
      "10 27.042844923858063 0.6193073593073594\n",
      "100 32.34814733209342 0.6250574063617542\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    linear = Linear(lambda_reg=lambda_reg)\n",
    "    linear_train_eval = linear.evaluate_over_years(train_years, season_male, world_male)\n",
    "    print(lambda_reg, linear_train_eval['rmse'].mean(), linear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsiq7aLDK45s"
   },
   "source": [
    "## Log-linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hrHEaiE_K45u",
    "outputId": "10b0eeac-ecdc-4aec-9965-8a262faede75",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "       -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_log_linear = np.linalg.inv(X.T @ X) @ (X.T @ np.log(y))\n",
    "coefs_log_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "q_rBARAlK45z",
    "outputId": "5c39cfa2-588b-4a0e-bb8e-313ab4a81d92",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_linear_rmse = np.exp(np.sqrt(np.mean((np.log(y) - X @ coefs_log_linear)**2)))\n",
    "log_linear_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DldaX6oFK452"
   },
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_log_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_log_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "skater_scores = np.exp(skater_scores)\n",
    "event_scores = np.exp(event_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1092
    },
    "colab_type": "code",
    "id": "acBrwPQmK456",
    "outputId": "65f9bce0-101f-4fb0-8bd2-4849f6eb88d9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  1.154228\n",
       "Nathan, CHEN                   1.110905\n",
       "Javier, FERNANDEZ              1.108103\n",
       "Shoma, UNO                     1.105957\n",
       "Patrick, CHAN                  1.062009\n",
       "Denis, TEN                     1.059121\n",
       "Boyang, JIN                    1.014664\n",
       "Adam, RIPPON                   1.000000\n",
       "Jason, BROWN                   0.953747\n",
       "Sergei, VORONOV                0.947786\n",
       "Alexei, BYCHENKO               0.937530\n",
       "Mikhail, KOLYADA               0.933023\n",
       "Takahito, MURA                 0.932946\n",
       "Max, AARON                     0.928603\n",
       "Kevin, REYNOLDS                0.912023\n",
       "Maxim, KOVTUN                  0.911407\n",
       "Misha, GE                      0.906351\n",
       "Keiji, TANAKA                  0.905789\n",
       "Nam, NGUYEN                    0.898441\n",
       "Alexander, PETROV              0.892819\n",
       "Jorik, HENDRICKX               0.891376\n",
       "Moris, KVITELASHVILI           0.880480\n",
       "Timothy, DOLENSKY              0.877638\n",
       "Han, YAN                       0.875485\n",
       "Gordei, GORSHKOV               0.869104\n",
       "Daniel, SAMOHIN                0.867256\n",
       "Chafik, BESSEGHIER             0.865572\n",
       "Artur, DMITRIEV                0.860806\n",
       "Deniss, VASILJEVS              0.856720\n",
       "Alexander, SAMARIN             0.853385\n",
       "                                 ...   \n",
       "Michal, BREZINA                0.841853\n",
       "Elladj, BALDE                  0.835828\n",
       "Paul, FENTZ                    0.834829\n",
       "Grant, HOCHSTEIN               0.831686\n",
       "Brendan, KERRY                 0.822836\n",
       "Michael Christian, MARTINEZ    0.815368\n",
       "Ross, MINER                    0.807469\n",
       "Alexander, MAJOROV             0.775878\n",
       "Julian Zhi Jie, YEE            0.771658\n",
       "Ivan, RIGHINI                  0.753486\n",
       "Ivan, PAVLOV                   0.749886\n",
       "Sihyeong, LEE                  0.745196\n",
       "Jinseo, KIM                    0.742645\n",
       "Kevin, AYMOZ                   0.737319\n",
       "Graham, NEWBERRY               0.732107\n",
       "Stephane, WALKER               0.727227\n",
       "Javier, RAYA                   0.722792\n",
       "June Hyoung, LEE               0.714204\n",
       "Maurizio, ZANDRON              0.689007\n",
       "Jiri, BELOHRADSKY              0.671338\n",
       "Slavik, HAYRAPETYAN            0.668233\n",
       "Daniel Albert, NAURITS         0.650934\n",
       "Chih-I, TSAO                   0.645860\n",
       "Andrew, DODDS                  0.616999\n",
       "Mark, WEBSTER                  0.609308\n",
       "Valtter, VIRTANEN              0.606540\n",
       "Sondre, ODDVOLL BOE            0.601957\n",
       "Leslie, IP                     0.558707\n",
       "Kai Xiang, CHEW                0.527181\n",
       "Micah, TANG                    0.517015\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skater_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X95i96d3K46B"
   },
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WK7bDvFXK46B",
    "outputId": "f36f797e-0983-4f0b-b96e-1ec8154db11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "        -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472]), 0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, np.log(y))\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ek66_AZBK46G",
    "outputId": "6e58745f-468b-46e4-cb64-4ecc8a7130b6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.sqrt(mean_squared_error(np.log(y), X @ lin.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mlyxm0p1K46K"
   },
   "source": [
    "Evaluate Kendall's Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iw0VLAUyK46M"
   },
   "outputs": [],
   "source": [
    "log_linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "z1dm9iBGK46R",
    "outputId": "f8772e6d-3d06-4233-a703-d7e09dce67bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NT2vi4e3K46U"
   },
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9jkDgpmK46W"
   },
   "outputs": [],
   "source": [
    "class LogLinear(Linear):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ np.log(y))\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.log_predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        self.predicted_season_scores = np.exp(self.log_predicted_season_scores)\n",
    "        \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        log_squared_errors = (np.log(season_scores['score'].values) - self.log_predicted_season_scores)**2\n",
    "        log_rmse = np.sqrt(log_squared_errors.mean())\n",
    "        rmse = np.exp(log_rmse)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "mLm3xhtOK46d",
    "outputId": "de083404-f510-4189-e22d-d63d08e8ac9e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>1.051008</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.045100</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>1.042015</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1.042605</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>216</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.050437</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.040119</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>193</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.041869</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>213</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>1.040164</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.048652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      rmse       tau  conc  pairs\n",
       "0  2005  1.051008  0.666667   175    210\n",
       "1  2006  1.045100  0.636364   207    253\n",
       "2  2007  1.042015  0.601449   221    276\n",
       "3  2009  1.042605  0.565217   216    276\n",
       "4  2010  1.050437  0.714286   198    231\n",
       "5  2012  1.040119  0.525692   193    253\n",
       "6  2013  1.041869  0.683794   213    253\n",
       "7  2014  1.040164  0.828571   192    210\n",
       "8  2016  1.048652  0.673913   231    276\n",
       "9  2017  1.037668  0.731884   239    276"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear = LogLinear()\n",
    "loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_male, world_male)\n",
    "loglinear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fGMSqZ4QK46i",
    "outputId": "0481a57e-a3f5-4d77-fa47-8808a1abe147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627837380011293"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "a4QH9htPK46o",
    "outputId": "eba12d04-0844-4a0d-a5ca-f209276ea9fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.evaluate_over_years(train_years, season_male, world_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "YhXdgkz0K46u",
    "outputId": "fe983ef0-a580-4e88-9940-10eb30fed30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.043963617896676 0.6627837380011293\n",
      "0.001 1.043998390360219 0.6618520609824958\n",
      "0.01 1.0453133728174064 0.653425559947299\n",
      "0.1 1.0518538623368006 0.6394089968003012\n",
      "1 1.087499139738013 0.6379691323169585\n",
      "10 1.162036606713829 0.6258008658008658\n",
      "100 1.1945282438818492 0.6286598908338039\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    loglinear = LogLinear(lambda_reg=lambda_reg)\n",
    "    loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_male, world_male)\n",
    "    print(lambda_reg, loglinear_train_eval['rmse'].mean(), loglinear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXSghBKwK463"
   },
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fBvWi8PK465"
   },
   "outputs": [],
   "source": [
    "season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "skater_names = list(season_table.index)\n",
    "event_names = list(season_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pk446s8CK46_"
   },
   "outputs": [],
   "source": [
    "true_scores = season_table.values\n",
    "skater_scores = np.full(len(skater_names), 0.5)\n",
    "event_scores = np.full(len(event_names), 0.5)\n",
    "bias = 0.5\n",
    "\n",
    "alpha = 0.001\n",
    "rmses = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    diff = np.outer(skater_scores, event_scores) + bias - true_scores\n",
    "    skater_gradients = np.nansum(diff * event_scores, axis=1)\n",
    "    event_gradients = np.nansum(diff.T * skater_scores, axis=1)\n",
    "    bias_gradient = np.nansum(diff)\n",
    "    \n",
    "    event_scores = event_scores - alpha * event_gradients\n",
    "    skater_scores = skater_scores - alpha * skater_gradients\n",
    "    bias = bias - alpha * bias_gradient\n",
    "    rmse = np.sqrt(np.nanmean(diff**2))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1JFUED4iK47I",
    "outputId": "726e687f-9c6c-4d60-fe11-e165d4c11ccb",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.863043830654695"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "g6B2mBjRK47N",
    "outputId": "fac1513e-be0c-43a6-b158-a361bf758bb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8b28983160>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to Liberation Sans ('/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf') with score of 2.050000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1092
    },
    "colab_type": "code",
    "id": "BqnC68HSK47U",
    "outputId": "23bcf478-e5c6-469e-8710-ab7e34f3e318",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  11.368899\n",
       "Nathan, CHEN                   10.696464\n",
       "Javier, FERNANDEZ              10.567736\n",
       "Shoma, UNO                     10.562198\n",
       "Patrick, CHAN                   9.981089\n",
       "Denis, TEN                      9.937335\n",
       "Boyang, JIN                     9.312272\n",
       "Adam, RIPPON                    9.098090\n",
       "Jason, BROWN                    8.460356\n",
       "Sergei, VORONOV                 8.312755\n",
       "Takahito, MURA                  8.193166\n",
       "Alexei, BYCHENKO                8.080860\n",
       "Mikhail, KOLYADA                8.037651\n",
       "Max, AARON                      7.963655\n",
       "Maxim, KOVTUN                   7.855620\n",
       "Kevin, REYNOLDS                 7.832711\n",
       "Misha, GE                       7.763226\n",
       "Keiji, TANAKA                   7.620523\n",
       "Nam, NGUYEN                     7.619910\n",
       "Alexander, PETROV               7.541744\n",
       "Jorik, HENDRICKX                7.515032\n",
       "Moris, KVITELASHVILI            7.359118\n",
       "Timothy, DOLENSKY               7.334442\n",
       "Han, YAN                        7.329392\n",
       "Daniel, SAMOHIN                 7.153315\n",
       "Chafik, BESSEGHIER              7.084044\n",
       "Gordei, GORSHKOV                7.077550\n",
       "Artur, DMITRIEV                 7.000995\n",
       "Alexander, SAMARIN              6.979732\n",
       "Deniss, VASILJEVS               6.937469\n",
       "                                 ...    \n",
       "Paul, FENTZ                     6.719907\n",
       "Grant, HOCHSTEIN                6.708263\n",
       "Ryuju, HINO                     6.703980\n",
       "Elladj, BALDE                   6.637348\n",
       "Brendan, KERRY                  6.556827\n",
       "Michael Christian, MARTINEZ     6.451284\n",
       "Ross, MINER                     6.314202\n",
       "Alexander, MAJOROV              5.858490\n",
       "Julian Zhi Jie, YEE             5.824359\n",
       "Ivan, RIGHINI                   5.567713\n",
       "Ivan, PAVLOV                    5.530509\n",
       "Sihyeong, LEE                   5.444818\n",
       "Jinseo, KIM                     5.408229\n",
       "Kevin, AYMOZ                    5.354532\n",
       "Graham, NEWBERRY                5.281554\n",
       "Stephane, WALKER                5.213233\n",
       "Javier, RAYA                    5.151124\n",
       "June Hyoung, LEE                5.000291\n",
       "Maurizio, ZANDRON               4.678056\n",
       "Jiri, BELOHRADSKY               4.430653\n",
       "Slavik, HAYRAPETYAN             4.387176\n",
       "Daniel Albert, NAURITS          4.144949\n",
       "Chih-I, TSAO                    4.020037\n",
       "Andrew, DODDS                   3.606092\n",
       "Valtter, VIRTANEN               3.523336\n",
       "Mark, WEBSTER                   3.495779\n",
       "Sondre, ODDVOLL BOE             3.459157\n",
       "Leslie, IP                      2.770009\n",
       "Kai Xiang, CHEW                 2.317837\n",
       "Micah, TANG                     2.172027\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_scores = pd.Series(skater_scores, index=skater_names)\n",
    "hybrid_scores.sort_values(ascending=False, inplace=True)\n",
    "hybrid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJFQsYRjK47c"
   },
   "outputs": [],
   "source": [
    "hybrid_ranking, world_ranking = return_ranking(hybrid_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iGgtFqplK47g",
    "outputId": "3607b9ac-0df1-462a-db74-73fb9152e9b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 238 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7246376811594203"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(hybrid_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRROmCe-K47s"
   },
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HioIZwt8K47w"
   },
   "outputs": [],
   "source": [
    "class Hybrid(Linear):\n",
    "    def __init__(self, alpha, n_factors, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        self.alpha = alpha\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "    def predict_season_scores(self, season_scores, bias=False):\n",
    "        predicted_score_table = (self.skater_scores @ self.event_scores.T + self.baseline)\n",
    "        if bias:\n",
    "            predicted_score_table = predicted_score_table + self.skater_bias[:, np.newaxis] + self.event_bias\n",
    "                                 \n",
    "        predicted_score_table = pd.DataFrame(predicted_score_table,\n",
    "                                            index=self.skater_names,\n",
    "                                            columns=self.event_names)   \n",
    "        predicted_score_stacked = predicted_score_table.stack()\n",
    "        season_skater_event_index = season_scores.set_index(['name', 'event']).index\n",
    "        self.predicted_season_scores = predicted_score_stacked.loc[season_skater_event_index].values\n",
    "        \n",
    "    def fit(self, season_scores, n_iter, seed=42, fixed_baseline=False, bias=False, verbose=False):\n",
    "        if verbose:\n",
    "            logging.disable(logging.NOTSET)\n",
    "        else:\n",
    "            logging.disable(logging.DEBUG)\n",
    "        season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "        self.skater_names = list(season_table.index)\n",
    "        self.event_names = list(season_table.columns)\n",
    "\n",
    "        true_scores = season_table.values\n",
    "        random_state = np.random.RandomState(seed=seed)\n",
    "        self.skater_scores = random_state.random_sample((len(self.skater_names), self.n_factors))\n",
    "        self.event_scores = random_state.random_sample((len(self.event_names), self.n_factors))\n",
    "        self.baseline = season_scores['score'].mean() if fixed_baseline else 0.5\n",
    "        self.skater_bias = random_state.random_sample(len(self.skater_names))\n",
    "        self.event_bias = random_state.random_sample(len(self.event_names))\n",
    "\n",
    "        self.rmses = []\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            logging.debug(f'iteration: {iteration}')\n",
    "            diff = self.skater_scores @ self.event_scores.T + self.baseline - true_scores\n",
    "            if bias:\n",
    "                diff = diff + self.skater_bias[:, np.newaxis] + self.event_bias\n",
    "            \n",
    "            for i in range(self.n_factors):\n",
    "                logging.debug(f'factor: {i}')\n",
    "                if not fixed_baseline:\n",
    "                    logging.debug(f'baseline before: {self.baseline}')\n",
    "                    baseline_gradient = np.nansum(diff)\n",
    "                    self.baseline = self.baseline - self.alpha * baseline_gradient\n",
    "                    logging.debug(f'baseline after: {self.baseline}')\n",
    "                if bias:\n",
    "                    logging.debug(f'skater_bias before: {self.event_bias}')\n",
    "                    logging.debug(f'event_bias before: {self.skater_bias}')                    \n",
    "                    self.skater_bias = self.skater_bias - self.alpha * (np.nansum(diff, axis=1) - self.lambda_reg * self.skater_bias)\n",
    "                    self.event_bias = self.event_bias - self.alpha * (np.nansum(diff, axis=0) - self.lambda_reg * self.event_bias)\n",
    "                    logging.debug(f'skater_bias after: {self.event_bias}')\n",
    "                    logging.debug(f'event_bias after: {self.skater_bias}')   \n",
    "                    \n",
    "                logging.debug(f'skater_scores before\\n{self.skater_scores}')\n",
    "                logging.debug(f'event_scores before\\n{self.event_scores}')                               \n",
    "                skater_gradients = np.nansum(diff * self.event_scores[:, i], axis=1) + self.lambda_reg * self.skater_scores[:, i]\n",
    "                event_gradients = np.nansum(diff.T * self.skater_scores[:, i], axis=1) + self.lambda_reg * self.event_scores[:, i] \n",
    "                logging.debug(f'skater_gradients\\n{skater_gradients}')\n",
    "                logging.debug(f'event_gradients\\n{event_gradients}')\n",
    "                \n",
    "                self.skater_scores[:, i] = self.skater_scores[:, i] - self.alpha * skater_gradients\n",
    "                self.event_scores[:, i] = self.event_scores[:, i] - self.alpha * event_gradients\n",
    "                logging.debug(f'skater_scores after\\n{self.skater_scores}')\n",
    "                logging.debug(f'event_scores after\\n{self.event_scores}')\n",
    "                \n",
    "            rmse = np.sqrt(np.nanmean(diff**2))\n",
    "            self.rmses.append(rmse)\n",
    "            \n",
    "        self.predict_season_scores(season_scores)\n",
    "        \n",
    "        if bias:\n",
    "            self.skater_scores = np.hstack([self.skater_bias[:, np.newaxis], self.skater_scores])\n",
    "            self.event_scores = np.hstack([self.event_bias[:, np.newaxis], self.event_scores])\n",
    "        \n",
    "        self.skater_scores = pd.DataFrame(self.skater_scores, index=self.skater_names)\n",
    "        self.event_scores = pd.DataFrame(self.event_scores, index=self.event_names)\n",
    "        \n",
    "        self.skater_scores.sort_values(by=0, ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(by=0, ascending=False, inplace=True)\n",
    "        \n",
    "\n",
    "    def evaluate_rmse_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        # Evaluate RMSE (without evaluating tau) over years\n",
    "        rmses = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            rmses.append(rmse)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yn_m5OqiK474"
   },
   "source": [
    "### Single latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5d5kC22K476",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1)\n",
    "hybrid.fit(season_scores, n_iter=1000, seed=42, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSdUj6eIK48K"
   },
   "source": [
    "Train over all years in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.632665</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>174</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.963977</td>\n",
       "      <td>0.612648</td>\n",
       "      <td>204</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.608671</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.188956</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.733415</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>195</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.317618</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>198</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>8.902550</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.802909</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>10.975994</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.863038</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>238</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.632665  0.657143   174    210\n",
       "1  2006   7.963977  0.612648   204    253\n",
       "2  2007   7.608671  0.630435   225    276\n",
       "3  2009   8.188956  0.601449   221    276\n",
       "4  2010   9.733415  0.688312   195    231\n",
       "5  2012   8.317618  0.565217   198    253\n",
       "6  2013   8.902550  0.691700   214    253\n",
       "7  2014   8.802909  0.828571   192    210\n",
       "8  2016  10.975994  0.695652   234    276\n",
       "9  2017   8.863038  0.724638   238    276"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_male, world_male, \n",
    "                    n_iter=1000, seed=42)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing baseline to be the overall average of season scores worsens ranking prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "wCIUCm7pK48L",
    "outputId": "d830070e-076b-420b-e0cd-c5d93fa1ef9f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.095679</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>161</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>10.894324</td>\n",
       "      <td>0.533597</td>\n",
       "      <td>194</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>9.388091</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>198</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>14.153183</td>\n",
       "      <td>0.514493</td>\n",
       "      <td>209</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>10.920079</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>159</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>13.262321</td>\n",
       "      <td>0.367589</td>\n",
       "      <td>173</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>14.734613</td>\n",
       "      <td>-0.162055</td>\n",
       "      <td>106</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>11.806984</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>174</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>13.454922</td>\n",
       "      <td>0.340580</td>\n",
       "      <td>185</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>9.755106</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.095679  0.533333   161    210\n",
       "1  2006  10.894324  0.533597   194    253\n",
       "2  2007   9.388091  0.434783   198    276\n",
       "3  2009  14.153183  0.514493   209    276\n",
       "4  2010  10.920079  0.376623   159    231\n",
       "5  2012  13.262321  0.367589   173    253\n",
       "6  2013  14.734613 -0.162055   106    253\n",
       "7  2014  11.806984  0.657143   174    210\n",
       "8  2016  13.454922  0.340580   185    276\n",
       "9  2017   9.755106  0.673913   231    276"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_male, world_male, \n",
    "                    n_iter=1000, seed=42, fixed_baseline=True)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqGzuUQJK48Q"
   },
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "H4L19RAQK48W",
    "outputId": "305670df-81e6-4668-ab84-4b0544b6b683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.798979360662049 0.6695765104460756\n",
      "0.1 8.799759095040118 0.670301148127235\n",
      "1 8.810396043402644 0.6742179559570863\n",
      "2 8.83064677895199 0.6726821005081874\n",
      "5 8.97079996177913 0.6711123658949745\n",
      "10 9.430037409643006 0.6663429324298888\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.1, 1, 2, 5, 10]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.001, n_factors=1)\n",
    "    hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_male, world_male, \n",
    "                                                   n_iter=1000, seed=42)\n",
    "    print(lambda_reg, hybrid_train_eval['rmse'].mean(), hybrid_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "E56u-EIDK48i",
    "outputId": "e515ba25-e6ec-4ea0-a1ae-cd38f32b0816"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.664557</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>8.004965</td>\n",
       "      <td>0.612648</td>\n",
       "      <td>204</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.611613</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.203703</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>222</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.727023</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>195</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.350502</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>199</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>8.883579</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.816281</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>10.971148</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>236</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.870589</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.664557  0.666667   175    210\n",
       "1  2006   8.004965  0.612648   204    253\n",
       "2  2007   7.611613  0.630435   225    276\n",
       "3  2009   8.203703  0.608696   222    276\n",
       "4  2010   9.727023  0.688312   195    231\n",
       "5  2012   8.350502  0.573123   199    253\n",
       "6  2013   8.883579  0.691700   214    253\n",
       "7  2014   8.816281  0.828571   192    210\n",
       "8  2016  10.971148  0.710145   236    276\n",
       "9  2017   8.870589  0.731884   239    276"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=1)\n",
    "hybrid.fit(season_scores, n_iter=1000, seed=42)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_male, world_male, \n",
    "                    n_iter=1000, seed=42)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "GUv2g5uRK48x",
    "outputId": "9176e898-d037-449c-a5d8-68ec740409c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.76233914400621 0.5993788819875776\n",
      "1 8.768670503824064 0.6011904761904762\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 1]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.001, n_factors=1)\n",
    "    hybrid_test_eval = hybrid.evaluate_over_years(test_years, season_male, world_male,\n",
    "                                                  n_iter=1000, seed=42)\n",
    "    print(lambda_reg, hybrid_test_eval['rmse'].mean(), hybrid_test_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qR7_lvNqK482",
    "outputId": "e31bc1cf-721f-4b59-ed4b-f9c92d027bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6094955768868812"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_test_eval = avg.evaluate_over_years(test_years, season_male, world_male)\n",
    "avg_test_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUP3sBU8K486"
   },
   "source": [
    "### Multiple latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1776CPAPK48-",
    "outputId": "a434cec5-95c3-4b16-9c27-132e695caddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2016, 2006, 2012, 2005, 2014], [2007, 2009, 2010, 2013, 2017])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = np.random.RandomState(seed=42)\n",
    "f1_years = list(random_state.choice(train_years, 5, replace=False))\n",
    "f2_years = [year for year in train_years if year not in f1_years]\n",
    "f1_years, f2_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FT4eOe4JRnbn"
   },
   "outputs": [],
   "source": [
    "class HybridLog:\n",
    "    def __init__(self, n_factors, hybrid_lambda,\n",
    "              hybrid_alpha=0.001, hybrid_iter=1000, hybrid_seed=42,\n",
    "              log_alpha=0.001, log_iter=1000, bias=False):\n",
    "        self.n_factors = n_factors\n",
    "        self.hybrid_lambda = hybrid_lambda\n",
    "        self.hybrid_alpha = hybrid_alpha\n",
    "        self.hybrid_iter = hybrid_iter\n",
    "        self.hybrid_seed = hybrid_seed\n",
    "        self.log_alpha = log_alpha\n",
    "        self.log_iter = log_iter\n",
    "        self.bias = bias\n",
    "\n",
    "    \n",
    "    def fit_hybrid(self, season_df, world_df, train_years):\n",
    "    # Train hybrid model on each training years to get latent factor values\n",
    "        all_pair_diffs = {}\n",
    "        for year in train_years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            hybrid = Hybrid(alpha=self.hybrid_alpha, n_factors=self.n_factors, lambda_reg=self.hybrid_lambda)\n",
    "            hybrid.fit(season_scores, n_iter=self.hybrid_iter, seed=self.hybrid_seed, bias=self.bias)\n",
    "            hybrid_skater_scores = hybrid.skater_scores\n",
    "\n",
    "            normalized_scores = (hybrid_skater_scores - hybrid_skater_scores.mean(axis=0)) / hybrid_skater_scores.std(axis=0)\n",
    "            normalized_scores = normalized_scores.reindex(world_scores.index).dropna()\n",
    "\n",
    "            pair_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normalized_scores.values, 2)))\n",
    "            all_pair_diffs[year] = pair_diffs\n",
    "\n",
    "        # Train logistic regression on pairwise differences of latent factor values\n",
    "        self.X_train = np.vstack((all_pair_diffs[year] for year in train_years))\n",
    "        self.y_train = np.full(len(self.X_train), 1)\n",
    "\n",
    "    \n",
    "    def fit_log(self, log_lambda):\n",
    "        log = BatchLogistic(theta=np.full(self.X_train.shape[1], 0.5), alpha=self.log_alpha, \n",
    "                            lambda_reg=log_lambda)\n",
    "        log.fit(self.X_train, self.y_train, n_iter=self.log_iter)\n",
    "        self.log_coefs = log.theta\n",
    "\n",
    "    \n",
    "    def predict(self, season_scores):\n",
    "        hybrid = Hybrid(alpha=self.hybrid_alpha, n_factors=self.n_factors, lambda_reg=self.hybrid_lambda)\n",
    "        hybrid.fit(season_scores, n_iter=self.hybrid_iter, seed=self.hybrid_seed, bias=self.bias)    \n",
    "        hybrid_skater_scores = hybrid.skater_scores\n",
    "\n",
    "        normalized_scores = (hybrid_skater_scores - hybrid_skater_scores.mean(axis=0)) / hybrid_skater_scores.std(axis=0)    \n",
    "        combined_scores = pd.Series(normalized_scores @ self.log_coefs, index=normalized_scores.index)\n",
    "        combined_scores.sort_values(ascending=False, inplace=True)\n",
    "        return combined_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1vAya73xckm"
   },
   "outputs": [],
   "source": [
    "def average_kendall_tau(hybridlog, years, season_df, world_df):\n",
    "    kendall_taus = []\n",
    "    for year in years:\n",
    "        season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "        combined_scores = hybridlog.predict(season_scores)\n",
    "        combined_ranking, world_ranking = return_ranking(combined_scores, world_scores)\n",
    "        kendall_tau = calculate_kendall_tau(combined_ranking, world_ranking, verbose=False)\n",
    "        kendall_taus.append(kendall_tau)\n",
    "\n",
    "    return np.array(kendall_taus).mean()\n",
    "\n",
    "\n",
    "def get_tau_train_val(season_df, world_df, train_years, val_years,\n",
    "                      hybridlog, log_lambda):\n",
    "    hybridlog.fit_log(log_lambda)\n",
    "    avg_tau_train = average_kendall_tau(hybridlog, train_years, season_df, world_df)\n",
    "    avg_tau_val = average_kendall_tau(hybridlog, val_years, season_df, world_df)\n",
    "    return avg_tau_train, avg_tau_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1127
    },
    "colab_type": "code",
    "id": "iHSTTISDsQ4U",
    "outputId": "d270faf0-cb68-4f3d-ac58-ac1dbaed7206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_factor: 5, hybrid_lambda: 0, log_lambda: 0\n",
      "f1_train: 0.6869602860907209, f1_val: 0.6594579333709769, f2_train: 0.6604178430265387, f2_val: 0.6651006964050442\n"
     ]
    }
   ],
   "source": [
    "n_factors = []\n",
    "hybrid_lambdas = []\n",
    "log_lambdas = []\n",
    "f1_tau_trains = []\n",
    "f1_tau_vals = []\n",
    "f2_tau_trains = []\n",
    "f2_tau_vals = []\n",
    "\n",
    "n_iter = 1000\n",
    "for n_factor in [5]:\n",
    "    for hybrid_lambda in [0]:\n",
    "        n_factors.append(n_factor)\n",
    "        hybrid_lambdas.append(hybrid_lambda)\n",
    "\n",
    "        # Train hybrid models on each fold\n",
    "        hybridlog1 = HybridLog(n_factors=n_factor, hybrid_lambda=hybrid_lambda,\n",
    "                            hybrid_alpha=0.001, hybrid_iter=n_iter, hybrid_seed=42,\n",
    "                            log_alpha=0.001, log_iter=n_iter, bias=True)\n",
    "        hybridlog1.fit_hybrid(season_male, world_male, f1_years)\n",
    "\n",
    "        hybridlog2 = HybridLog(n_factors=n_factor, hybrid_lambda=hybrid_lambda,\n",
    "                            hybrid_alpha=0.001, hybrid_iter=n_iter, hybrid_seed=42,\n",
    "                            log_alpha=0.001, log_iter=n_iter, bias=True)\n",
    "        hybridlog2.fit_hybrid(season_male, world_male, f2_years)\n",
    "      \n",
    "      # Train log models on each fold and evaluate kendall tau\n",
    "    for log_lambda in [0]:\n",
    "        print(f'n_factor: {n_factor}, hybrid_lambda: {hybrid_lambda}, log_lambda: {log_lambda}')\n",
    "        log_lambdas.append(log_lambda)\n",
    "        f1_tau_train, f1_tau_val = get_tau_train_val(season_male, world_male,\n",
    "                                                     f1_years, f2_years,\n",
    "                                                     hybridlog1, log_lambda)\n",
    "        f2_tau_train, f2_tau_val = get_tau_train_val(season_male, world_male,\n",
    "                                                     f2_years, f1_years,\n",
    "                                                     hybridlog2, log_lambda)\n",
    "        print(f'f1_train: {f1_tau_train}, f1_val: {f1_tau_val}, f2_train: {f2_tau_train}, f2_val: {f2_tau_val}')\n",
    "        \n",
    "        f1_tau_trains.append(f1_tau_train)\n",
    "        f1_tau_vals.append(f1_tau_val)\n",
    "        f2_tau_trains.append(f2_tau_train)\n",
    "        f2_tau_vals.append(f2_tau_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMDtjEthsQlk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_factor</th>\n",
       "      <th>hybrid_lambda</th>\n",
       "      <th>log_lambda</th>\n",
       "      <th>f1_tau_train</th>\n",
       "      <th>f1_tau_val</th>\n",
       "      <th>f2_tau_train</th>\n",
       "      <th>f2_tau_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672562</td>\n",
       "      <td>0.652964</td>\n",
       "      <td>0.662733</td>\n",
       "      <td>0.66274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_factor  hybrid_lambda  log_lambda  f1_tau_train  f1_tau_val  \\\n",
       "0         5              0           0      0.672562    0.652964   \n",
       "\n",
       "   f2_tau_train  f2_tau_val  \n",
       "0      0.662733     0.66274  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons = pd.DataFrame({'n_factor': n_factors, 'hybrid_lambda': hybrid_lambdas, 'log_lambda': log_lambdas,\n",
    "'f1_tau_train': f1_tau_trains, 'f1_tau_val': f1_tau_vals,\n",
    "'f2_tau_train': f2_tau_trains, 'f2_tau_val': f2_tau_vals})\n",
    "comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDPHxE8ljsts"
   },
   "outputs": [],
   "source": [
    "comparisons.to_csv('comparisons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58SdnNobqR9D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
