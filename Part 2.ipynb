{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "skater_names = list(season_table.index)\n",
    "event_names = list(season_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scores = season_table.values\n",
    "skater_scores = np.full(len(skater_names), 0.5)\n",
    "event_scores = np.full(len(event_names), 0.5)\n",
    "bias = 0.5\n",
    "\n",
    "alpha = 0.001\n",
    "rmses = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    diff = np.outer(skater_scores, event_scores) + bias - true_scores\n",
    "    skater_gradients = np.nansum(diff * event_scores, axis=1)\n",
    "    event_gradients = np.nansum(diff.T * skater_scores, axis=1)\n",
    "    bias_gradient = np.nansum(diff)\n",
    "    \n",
    "    event_scores = event_scores - alpha * event_gradients\n",
    "    skater_scores = skater_scores - alpha * skater_gradients\n",
    "    bias = bias - alpha * bias_gradient\n",
    "    rmse = np.sqrt(np.nanmean(diff**2))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.863043830654695"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f590e1f0d30>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  11.368899\n",
       "Nathan, CHEN                   10.696464\n",
       "Javier, FERNANDEZ              10.567736\n",
       "Shoma, UNO                     10.562198\n",
       "Patrick, CHAN                   9.981089\n",
       "Denis, TEN                      9.937335\n",
       "Boyang, JIN                     9.312272\n",
       "Adam, RIPPON                    9.098090\n",
       "Jason, BROWN                    8.460356\n",
       "Sergei, VORONOV                 8.312755\n",
       "Takahito, MURA                  8.193166\n",
       "Alexei, BYCHENKO                8.080860\n",
       "Mikhail, KOLYADA                8.037651\n",
       "Max, AARON                      7.963655\n",
       "Maxim, KOVTUN                   7.855620\n",
       "Kevin, REYNOLDS                 7.832711\n",
       "Misha, GE                       7.763226\n",
       "Keiji, TANAKA                   7.620523\n",
       "Nam, NGUYEN                     7.619910\n",
       "Alexander, PETROV               7.541744\n",
       "Jorik, HENDRICKX                7.515032\n",
       "Moris, KVITELASHVILI            7.359118\n",
       "Timothy, DOLENSKY               7.334442\n",
       "Han, YAN                        7.329392\n",
       "Daniel, SAMOHIN                 7.153315\n",
       "Chafik, BESSEGHIER              7.084044\n",
       "Gordei, GORSHKOV                7.077550\n",
       "Artur, DMITRIEV                 7.000995\n",
       "Alexander, SAMARIN              6.979732\n",
       "Deniss, VASILJEVS               6.937469\n",
       "                                 ...    \n",
       "Paul, FENTZ                     6.719907\n",
       "Grant, HOCHSTEIN                6.708263\n",
       "Ryuju, HINO                     6.703980\n",
       "Elladj, BALDE                   6.637348\n",
       "Brendan, KERRY                  6.556827\n",
       "Michael Christian, MARTINEZ     6.451284\n",
       "Ross, MINER                     6.314202\n",
       "Alexander, MAJOROV              5.858490\n",
       "Julian Zhi Jie, YEE             5.824359\n",
       "Ivan, RIGHINI                   5.567713\n",
       "Ivan, PAVLOV                    5.530509\n",
       "Sihyeong, LEE                   5.444818\n",
       "Jinseo, KIM                     5.408229\n",
       "Kevin, AYMOZ                    5.354532\n",
       "Graham, NEWBERRY                5.281554\n",
       "Stephane, WALKER                5.213233\n",
       "Javier, RAYA                    5.151124\n",
       "June Hyoung, LEE                5.000291\n",
       "Maurizio, ZANDRON               4.678056\n",
       "Jiri, BELOHRADSKY               4.430653\n",
       "Slavik, HAYRAPETYAN             4.387176\n",
       "Daniel Albert, NAURITS          4.144949\n",
       "Chih-I, TSAO                    4.020037\n",
       "Andrew, DODDS                   3.606092\n",
       "Valtter, VIRTANEN               3.523336\n",
       "Mark, WEBSTER                   3.495779\n",
       "Sondre, ODDVOLL BOE             3.459157\n",
       "Leslie, IP                      2.770009\n",
       "Kai Xiang, CHEW                 2.317837\n",
       "Micah, TANG                     2.172027\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_scores = pd.Series(skater_scores, index=skater_names)\n",
    "hybrid_scores.sort_values(ascending=False, inplace=True)\n",
    "hybrid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_ranking, world_ranking = return_ranking(hybrid_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 238 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7246376811594203"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(hybrid_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(Linear):\n",
    "    def __init__(self, alpha, n_factors, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        self.alpha = alpha\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        predicted_score_table = pd.DataFrame(self.skater_scores.values @ self.event_scores.values.T + self.baseline,\n",
    "                                            index=self.skater_scores.index,\n",
    "                                            columns=self.event_scores.index)\n",
    "        \n",
    "        predicted_score_stacked = predicted_score_table.stack()\n",
    "        season_skater_event_index = season_scores.set_index(['name', 'event']).index\n",
    "        self.predicted_season_scores = predicted_score_stacked.loc[season_skater_event_index].values\n",
    "        \n",
    "    def fit(self, season_scores, n_iter, seed=42, fixed_baseline=False, verbose=False):\n",
    "        if verbose:\n",
    "            logging.disable(logging.NOTSET)\n",
    "        else:\n",
    "            logging.disable(logging.DEBUG)\n",
    "        season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "        skater_names = list(season_table.index)\n",
    "        event_names = list(season_table.columns)\n",
    "\n",
    "        true_scores = season_table.values\n",
    "        random_state = np.random.RandomState(seed=seed)\n",
    "        self.skater_scores = random_state.random_sample((len(skater_names), self.n_factors))\n",
    "        self.event_scores = random_state.random_sample((len(event_names), self.n_factors))\n",
    "        self.baseline = season_scores['score'].mean() if fixed_baseline else 0.5\n",
    "\n",
    "        self.rmses = []\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            logging.debug(f'iteration: {iteration}')\n",
    "            diff = self.skater_scores @ self.event_scores.T + self.baseline - true_scores\n",
    "            \n",
    "            for i in range(self.n_factors):\n",
    "                logging.debug(f'i: {i}')\n",
    "                if not fixed_baseline:\n",
    "                    baseline_gradient = np.nansum(diff)\n",
    "                    self.baseline = self.baseline - self.alpha * baseline_gradient\n",
    "                    \n",
    "                logging.debug(f'skater_scores before\\n{self.skater_scores}')\n",
    "                logging.debug(f'event_scores before\\n{self.event_scores}')                               \n",
    "                skater_gradients = np.nansum(diff * self.event_scores[:, i], axis=1) + self.lambda_reg * self.skater_scores[:, i]\n",
    "                event_gradients = np.nansum(diff.T * self.skater_scores[:, i], axis=1) + self.lambda_reg * self.event_scores[:, i] \n",
    "                logging.debug(f'skater_gradients\\n{skater_gradients}')\n",
    "                logging.debug(f'event_gradients\\n{event_gradients}')\n",
    "                \n",
    "                self.skater_scores[:, i] = self.skater_scores[:, i] - self.alpha * skater_gradients\n",
    "                self.event_scores[:, i] = self.event_scores[:, i] - self.alpha * event_gradients\n",
    "                logging.debug(f'skater_scores after\\n{self.skater_scores}')\n",
    "                logging.debug(f'event_scores after\\n{self.event_scores}')\n",
    "                \n",
    "            rmse = np.sqrt(np.nanmean(diff**2))\n",
    "            self.rmses.append(rmse)\n",
    "\n",
    "        self.skater_scores = pd.DataFrame(self.skater_scores, index=skater_names)\n",
    "        self.event_scores = pd.DataFrame(self.event_scores, index=event_names)\n",
    "        \n",
    "        self.skater_scores.sort_values(by=0, ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(by=0, ascending=False, inplace=True)\n",
    "        \n",
    "        self.predict_season_scores(season_scores)\n",
    "\n",
    "    def evaluate_rmse_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        rmses = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            rmses.append(rmse)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=10)\n",
    "hybrid.fit(season_scores, n_iter=1000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yuzuru, HANYU</th>\n",
       "      <td>9.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nathan, CHEN</th>\n",
       "      <td>7.737974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Javier, FERNANDEZ</th>\n",
       "      <td>7.563217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoma, UNO</th>\n",
       "      <td>7.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patrick, CHAN</th>\n",
       "      <td>6.425772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "Yuzuru, HANYU      9.311300\n",
       "Nathan, CHEN       7.737974\n",
       "Javier, FERNANDEZ  7.563217\n",
       "Shoma, UNO         7.491667\n",
       "Patrick, CHAN      6.425772"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.skater_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EU</th>\n",
       "      <td>11.307682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C</th>\n",
       "      <td>10.576126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RU</th>\n",
       "      <td>9.723993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN</th>\n",
       "      <td>9.441479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>8.758149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "EU  11.307682\n",
       "4C  10.576126\n",
       "RU   9.723993\n",
       "CN   9.441479\n",
       "FR   8.758149"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.event_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train over all years in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>9.608030</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>171</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.165213</td>\n",
       "      <td>0.620553</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.982004</td>\n",
       "      <td>0.644928</td>\n",
       "      <td>227</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.743461</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>10.162420</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>197</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.995002</td>\n",
       "      <td>0.612648</td>\n",
       "      <td>204</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.202840</td>\n",
       "      <td>0.644269</td>\n",
       "      <td>208</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>9.472834</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.426683</td>\n",
       "      <td>0.688406</td>\n",
       "      <td>233</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>9.541887</td>\n",
       "      <td>0.688406</td>\n",
       "      <td>233</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   9.608030  0.628571   171    210\n",
       "1  2006   9.165213  0.620553   205    253\n",
       "2  2007   7.982004  0.644928   227    276\n",
       "3  2009   8.743461  0.601449   221    276\n",
       "4  2010  10.162420  0.705628   197    231\n",
       "5  2012   8.995002  0.612648   204    253\n",
       "6  2013   9.202840  0.644269   208    253\n",
       "7  2014   9.472834  0.828571   192    210\n",
       "8  2016  11.426683  0.688406   233    276\n",
       "9  2017   9.541887  0.688406   233    276"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=10)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n",
    "                    n_iter=1000, seed=42)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.798979360662049 0.6695765104460756\n",
      "0.1 8.799759095040118 0.670301148127235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-35365a373ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhybrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHybrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n\u001b[0;32m----> 4\u001b[0;31m                                                    n_iter=1000, seed=42)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_train_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_train_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-67a0aaa44317>\u001b[0m in \u001b[0;36mevaluate_over_years\u001b[0;34m(self, years, season_df, world_df, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mseason_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yearly_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcordant_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kendall_tau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-45b353a177f4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, season_scores, n_iter, seed, fixed_baseline, verbose)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mskater_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskater_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mevent_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskater_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'skater_gradients\\n{skater_gradients}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'event_gradients\\n{event_gradients}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray_str\u001b[0;34m(a, max_line_width, precision, suppress_small)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_guarded_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_string_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, **kwarg)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    459\u001b[0m     lst = _formatArray(a, format_function, options['linewidth'],\n\u001b[1;32m    460\u001b[0m                        \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edgeitems'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                        summary_insert, options['legacy'])\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, line_width, next_line_prefix, separator, edge_items, summary_insert, legacy)\u001b[0m\n\u001b[1;32m    759\u001b[0m         return recurser(index=(),\n\u001b[1;32m    760\u001b[0m                         \u001b[0mhanging_indent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                         curr_width=line_width)\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;31m# recursive closures have a cyclic reference to themselves, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrailing_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_hanging_indent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                 s, line = _extendLine(\n\u001b[1;32m    717\u001b[0m                     s, line, word, elem_width, hanging_indent, legacy)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxes_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformat_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# when recursing, add a space to align with the [ added, and reduce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                       \u001b[0msign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                       \u001b[0mpad_left\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_left\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                                       pad_right=self.pad_right)\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;31m# for back-compatibility, we keep the classes for each float type too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.1, 1, 2, 5, 10]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.001, n_factors=1)\n",
    "    hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n",
    "                                                   n_iter=1000, seed=42)\n",
    "    print(lambda_reg, hybrid_train_eval['rmse'].mean(), hybrid_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=1)\n",
    "hybrid.fit(season_scores, n_iter=1000, seed=42)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n",
    "                    n_iter=1000, seed=42)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambda_reg in [0, 1]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.001, n_factors=1)\n",
    "    hybrid_test_eval = hybrid.evaluate_over_years(test_years, season_test, world_test,\n",
    "                                                  n_iter=1000, seed=42)\n",
    "    print(lambda_reg, hybrid_test_eval['rmse'].mean(), hybrid_test_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = AverageScore()\n",
    "avg_test_eval = avg.evaluate_over_years(test_years, season_test, world_test)\n",
    "avg_test_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(seed=42)\n",
    "f1_years = list(random_state.choice(train_years, 5, replace=False))\n",
    "f2_years = [year for year in train_years if year not in f1_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_and_world_scores(scores):\n",
    "    all_season_scores = {}\n",
    "    all_world_scores = {}\n",
    "\n",
    "    for year in range(2005, 2020):\n",
    "        season_scores = scores.loc[(scores['year']==year) & (scores['event']!='WR')].copy()\n",
    "        world_scores = scores.loc[(scores['year']==year) & (scores['event']=='WR'), ['name', 'score']]\n",
    "        world_scores = world_scores.set_index('name').squeeze()\n",
    "        all_season_scores[year] = season_scores\n",
    "        all_world_scores[year] = world_scores\n",
    "    return all_season_scores, all_world_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_season_scores, all_world_scores = get_season_and_world_scores(male_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_normalized_scores = {}\n",
    "all_pair_diffs = {}\n",
    "\n",
    "for year in train_years:\n",
    "    season_scores = all_season_scores[year]\n",
    "    world_scores = all_world_scores[year]\n",
    "    hybrid = Hybrid(alpha=0.001, n_factors=5, lambda_reg=10)\n",
    "    hybrid.fit(season_scores, n_iter=1000, seed=42)    \n",
    "    hybrid_scores = hybrid.skater_scores\n",
    "    \n",
    "    normalized_scores = (hybrid_scores - hybrid_scores.mean(axis=0)) / hybrid_scores.std(axis=0)\n",
    "    normalized_scores = normalized_scores.reindex(world_scores.index).dropna()\n",
    "    all_normalized_scores[year] = normalized_scores\n",
    "    \n",
    "    pair_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normalized_scores.values, 2)))\n",
    "    all_pair_diffs[year] = pair_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((all_pair_diffs[year] for year in f2_years))\n",
    "y_train = np.full(len(X_train), 1)\n",
    "n_coefs = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37336036, 0.80010816, 0.25238218, 0.38409724, 0.50886353])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = BatchLogistic(theta=np.full(n_coefs, 0.5), alpha=0.001, lambda_reg=10)\n",
    "log.fit(X_train, y_train, n_iter=1000)\n",
    "log.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "There are 237 concordant_pairs out of 276 pairs\n",
      "2006\n",
      "There are 205 concordant_pairs out of 253 pairs\n",
      "2012\n",
      "There are 199 concordant_pairs out of 253 pairs\n",
      "2005\n",
      "There are 173 concordant_pairs out of 210 pairs\n",
      "2014\n",
      "There are 191 concordant_pairs out of 210 pairs\n",
      "0.6755467720685113\n"
     ]
    }
   ],
   "source": [
    "f1_taus = []\n",
    "for year in f1_years:\n",
    "    print(year)\n",
    "    normalized_scores = all_normalized_scores[year]\n",
    "    combined_scores =  pd.Series(normalized_scores @ log.theta, index=normalized_scores.index)\n",
    "    combined_ranking, world_ranking = return_ranking(combined_scores, all_world_scores[year])\n",
    "    f1_taus.append(calculate_kendall_tau(combined_ranking, world_ranking))\n",
    "    \n",
    "print(np.array(f1_taus).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n",
      "There are 228 concordant_pairs out of 276 pairs\n",
      "2009\n",
      "There are 223 concordant_pairs out of 276 pairs\n",
      "2010\n",
      "There are 195 concordant_pairs out of 231 pairs\n",
      "2013\n",
      "There are 202 concordant_pairs out of 253 pairs\n",
      "2017\n",
      "There are 226 concordant_pairs out of 276 pairs\n",
      "0.638189346884999\n"
     ]
    }
   ],
   "source": [
    "f2_taus = []\n",
    "for year in f2_years:\n",
    "    print(year)\n",
    "    normalized_scores = all_normalized_scores[year]\n",
    "    combined_scores =  pd.Series(normalized_scores @ log.theta, index=normalized_scores.index)\n",
    "    combined_ranking, world_ranking = return_ranking(combined_scores, all_world_scores[year])\n",
    "    f2_taus.append(calculate_kendall_tau(combined_ranking, world_ranking))\n",
    "    \n",
    "print(np.array(f2_taus).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLog:\n",
    "    def __init__(self, n_factors, hybrid_lambda,\n",
    "              hybrid_alpha=0.001, hybrid_iter=1000, hybrid_seed=42,\n",
    "              log_alpha=0.001, log_iter=1000):\n",
    "        self.n_factors = n_factors\n",
    "        self.hybrid_lambda = hybrid_lambda\n",
    "        self.hybrid_alpha = hybrid_alpha\n",
    "        self.hybrid_iter = hybrid_iter\n",
    "        self.hybrid_seed = hybrid_seed\n",
    "        self.log_alpha = log_alpha\n",
    "        self.log_iter = log_iter\n",
    "\n",
    "    \n",
    "    def fit_hybrid(self, season_df, world_df, train_years):\n",
    "        # Train hybrid model on each training years to get latent factor values\n",
    "        all_pair_diffs = {}\n",
    "        for year in train_years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            hybrid = Hybrid(alpha=self.hybrid_alpha, n_factors=self.n_factors, lambda_reg=self.hybrid_lambda)\n",
    "            hybrid.fit(season_scores, n_iter=self.hybrid_iter, seed=self.hybrid_seed)\n",
    "            hybrid_skater_scores = hybrid.skater_scores\n",
    "\n",
    "            normalized_scores = (hybrid_skater_scores - hybrid_skater_scores.mean(axis=0)) / hybrid_skater_scores.std(axis=0)\n",
    "            normalized_scores = normalized_scores.reindex(world_scores.index).dropna()\n",
    "\n",
    "            pair_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normalized_scores.values, 2)))\n",
    "            all_pair_diffs[year] = pair_diffs\n",
    "\n",
    "        # Train logistic regression on pairwise differences of latent factor values\n",
    "        self.X_train = np.vstack((all_pair_diffs[year] for year in train_years))\n",
    "        self.y_train = np.full(len(self.X_train), 1)\n",
    "    \n",
    "    \n",
    "    def fit_log(self, log_lambda):\n",
    "        log = BatchLogistic(theta=np.full(self.n_factors, 0.5), alpha=self.log_alpha, \n",
    "                            lambda_reg=log_lambda)\n",
    "        log.fit(self.X_train, self.y_train, n_iter=self.log_iter)\n",
    "        self.log_coefs = log.theta\n",
    "\n",
    "    \n",
    "    def predict(self, season_scores):\n",
    "        hybrid = Hybrid(alpha=self.hybrid_alpha, n_factors=self.n_factors, lambda_reg=self.hybrid_lambda)\n",
    "        hybrid.fit(season_scores, n_iter=self.hybrid_iter, seed=self.hybrid_seed)    \n",
    "        hybrid_skater_scores = hybrid.skater_scores\n",
    "\n",
    "        normalized_scores = (hybrid_skater_scores - hybrid_skater_scores.mean(axis=0)) / hybrid_skater_scores.std(axis=0)    \n",
    "        combined_scores = pd.Series(normalized_scores @ self.log_coefs, index=normalized_scores.index)\n",
    "        combined_scores.sort_values(ascending=False, inplace=True)\n",
    "        return combined_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_kendall_tau(hybridlog, years, season_df, world_df):\n",
    "    kendall_taus = []\n",
    "    for year in years:\n",
    "        season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "        combined_scores = hybridlog.predict(season_scores)\n",
    "        combined_ranking, world_ranking = return_ranking(combined_scores, world_scores)\n",
    "        kendall_tau = calculate_kendall_tau(combined_ranking, world_ranking, verbose=False)\n",
    "        kendall_taus.append(kendall_tau)\n",
    "\n",
    "    return np.array(kendall_taus).mean()\n",
    "\n",
    "\n",
    "def get_tau_train_val(season_df, world_df, train_years, val_years,\n",
    "                      hybridlog, log_lambda):\n",
    "    hybridlog.fit_log(log_lambda)\n",
    "    avg_tau_train = average_kendall_tau(hybridlog, train_years, season_df, world_df)\n",
    "    avg_tau_val = average_kendall_tau(hybridlog, val_years, season_df, world_df)\n",
    "    return avg_tau_train, avg_tau_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_factor: 1, hybrid_lambda: 10, log_lambda: 10\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 205 concordant_pairs out of 253 pairs\n",
      "There are 204 concordant_pairs out of 253 pairs\n",
      "There are 171 concordant_pairs out of 210 pairs\n",
      "There are 192 concordant_pairs out of 210 pairs\n",
      "There are 227 concordant_pairs out of 276 pairs\n",
      "There are 221 concordant_pairs out of 276 pairs\n",
      "There are 197 concordant_pairs out of 231 pairs\n",
      "There are 208 concordant_pairs out of 253 pairs\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 227 concordant_pairs out of 276 pairs\n",
      "There are 221 concordant_pairs out of 276 pairs\n",
      "There are 197 concordant_pairs out of 231 pairs\n",
      "There are 208 concordant_pairs out of 253 pairs\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 205 concordant_pairs out of 253 pairs\n",
      "There are 204 concordant_pairs out of 253 pairs\n",
      "There are 171 concordant_pairs out of 210 pairs\n",
      "There are 192 concordant_pairs out of 210 pairs\n",
      "f1_train: 0.6757500470543949, f1_val: 0.656935817805383, f2_train: 0.656935817805383, f2_val: 0.6757500470543949\n"
     ]
    }
   ],
   "source": [
    "n_factors = []\n",
    "hybrid_lambdas = []\n",
    "log_lambdas = []\n",
    "f1_tau_trains = []\n",
    "f1_tau_vals = []\n",
    "f2_tau_trains = []\n",
    "f2_tau_vals = []\n",
    "\n",
    "n_iter = 1000\n",
    "for n_factor in [1, ]:\n",
    "    for hybrid_lambda in [10]:\n",
    "        n_factors.append(n_factor)\n",
    "        hybrid_lambdas.append(hybrid_lambda)\n",
    "\n",
    "        # Train hybrid models on each fold\n",
    "        hybridlog1 = HybridLog(n_factors=n_factor, hybrid_lambda=hybrid_lambda,\n",
    "                            hybrid_alpha=0.001, hybrid_iter=n_iter, hybrid_seed=42,\n",
    "                            log_alpha=0.001, log_iter=n_iter)\n",
    "        hybridlog1.fit_hybrid(season_male, world_male, f1_years)\n",
    "\n",
    "        hybridlog2 = HybridLog(n_factors=n_factor, hybrid_lambda=hybrid_lambda,\n",
    "                            hybrid_alpha=0.001, hybrid_iter=n_iter, hybrid_seed=42,\n",
    "                            log_alpha=0.001, log_iter=n_iter)\n",
    "        hybridlog2.fit_hybrid(season_male, world_male, f2_years)\n",
    "\n",
    "      # Train log models on each fold and evaluate kendall tau\n",
    "    for log_lambda in [10]:\n",
    "        print(f'n_factor: {n_factor}, hybrid_lambda: {hybrid_lambda}, log_lambda: {log_lambda}')\n",
    "        log_lambdas.append(log_lambda)\n",
    "        f1_tau_train, f1_tau_val = get_tau_train_val(season_male, world_male,\n",
    "                                                     f1_years, f2_years,\n",
    "                                                     hybridlog1, log_lambda)\n",
    "        f2_tau_train, f2_tau_val = get_tau_train_val(season_male, world_male,\n",
    "                                                     f2_years, f1_years,\n",
    "                                                     hybridlog2, log_lambda)\n",
    "        print(f'f1_train: {f1_tau_train}, f1_val: {f1_tau_val}, f2_train: {f2_tau_train}, f2_val: {f2_tau_val}')\n",
    "        f1_tau_trains.append(f1_tau_train)\n",
    "        f1_tau_vals.append(f1_tau_val)\n",
    "        f2_tau_trains.append(f2_tau_train)\n",
    "        f2_tau_vals.append(f2_tau_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_factor</th>\n",
       "      <th>hybrid_lambda</th>\n",
       "      <th>log_lambda</th>\n",
       "      <th>f1_tau_train</th>\n",
       "      <th>f1_tau_val</th>\n",
       "      <th>f2_tau_train</th>\n",
       "      <th>f2_tau_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67575</td>\n",
       "      <td>0.656936</td>\n",
       "      <td>0.656936</td>\n",
       "      <td>0.67575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_factor  hybrid_lambda  log_lambda  f1_tau_train  f1_tau_val  \\\n",
       "0         1             10          10       0.67575    0.656936   \n",
       "\n",
       "   f2_tau_train  f2_tau_val  \n",
       "0      0.656936     0.67575  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons = pd.DataFrame({'n_factor': n_factors, 'hybrid_lambda': hybrid_lambdas, 'log_lambda': log_lambdas,\n",
    "'f1_tau_train': f1_tau_trains, 'f1_tau_val': f1_tau_vals,\n",
    "'f2_tau_train': f2_tau_trains, 'f2_tau_val': f2_tau_vals})\n",
    "comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656935817805383"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_train_eval.loc[hybrid_train_eval['year'].isin(f2_years), 'tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
